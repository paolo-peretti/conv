{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "capsule.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOtOBHGYGLeZTGs83cZgnXZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paolo-peretti/conv/blob/main/capsule.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/adambielski/CapsNet-pytorch\n",
        "import sys, os\n",
        "sys.path.append('/content/CapsNet-Pytorch')\n",
        "os.chdir('/content/CapsNet-pytorch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu8h4aV6gyI_",
        "outputId": "ca15037e-f8dc-4a00-a3e0-76decfb8b2c0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CapsNet-pytorch'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Total 23 (delta 0), reused 0 (delta 0), pack-reused 23\u001b[K\n",
            "Unpacking objects: 100% (23/23), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "87g7dQwVlqgW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from net import CapsNetWithReconstruction, CapsNet, ReconstructionNet, MarginLoss"
      ],
      "metadata": {
        "id": "UxZzveohlw5-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Helper function for inline image display\n",
        "def imshow(img):\n",
        "    img = img.cpu()\n",
        "    # img = img / 2 + 0.5     # unnormalize\n",
        "    # npimg = img.numpy()\n",
        "    plt.imshow(img.resize(28,28))\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "ZLnNf85O1Icz"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "capsnet = CapsNet(3, 10)\n",
        "reconstructionnet = ReconstructionNet(16, 10)\n",
        "model = CapsNetWithReconstruction(capsnet, reconstructionnet)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQzh2RhIl08d",
        "outputId": "214f14e4-a007-4e33-9d99-70fd03ab6911"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CapsNetWithReconstruction(\n",
              "  (capsnet): CapsNet(\n",
              "    (conv1): Conv2d(1, 256, kernel_size=(9, 9), stride=(1, 1))\n",
              "    (primaryCaps): PrimaryCapsLayer(\n",
              "      (conv): Conv2d(256, 256, kernel_size=(9, 9), stride=(2, 2))\n",
              "    )\n",
              "    (digitCaps): CapsLayer(\n",
              "      (routing_module): AgreementRouting()\n",
              "    )\n",
              "  )\n",
              "  (reconstruction_net): ReconstructionNet(\n",
              "    (fc1): Linear(in_features=160, out_features=512, bias=True)\n",
              "    (fc2): Linear(in_features=512, out_features=1024, bias=True)\n",
              "    (fc3): Linear(in_features=1024, out_features=784, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MNIST('./data', train=False, transform=ToTensor(), download=True)"
      ],
      "metadata": {
        "id": "wdtSxHGxl79U"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "# PyTorch TensorBoard support\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "\n",
        "stats = ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "transform = transforms.Compose(\n",
        "    [transforms.RandomCrop(32, padding=4, padding_mode='reflect'), \n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(*stats,inplace=True)])\n",
        "\n",
        "\n",
        "# Create datasets for training & validation, download if necessary\n",
        "training_set = MNIST('./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "validation_set = MNIST('./data', train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "\n",
        "# Create data loaders for our datasets; shuffle for training, not for validation\n",
        "training_loader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "\n",
        "# Class labels\n",
        "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
        "\n",
        "# Report split sizes\n",
        "print('Training set has {} instances'.format(len(training_set)))\n",
        "print('Validation set has {} instances'.format(len(validation_set)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmAiKDdOprIB",
        "outputId": "95558bd1-612b-4f6f-e75f-c105d0bbb9a2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set has 60000 instances\n",
            "Validation set has 10000 instances\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import argparse\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "OLlul-HTnElD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=15, min_lr=1e-6)\n",
        "loss_fn = MarginLoss(0.9, 0.1, 0.5)\n",
        "reconstruction_alpha=0.0005"
      ],
      "metadata": {
        "id": "DFrhWur8nfjF"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(training_loader):\n",
        "\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    data, target = Variable(data), Variable(target, requires_grad=False)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # with reconstruction\n",
        "    output, probs = model(data, target)\n",
        "    \n",
        "    reconstruction_loss = F.mse_loss(output, data.view(-1, 784))\n",
        "    margin_loss = loss_fn(probs, target)\n",
        "    loss = reconstruction_alpha * reconstruction_loss + margin_loss\n",
        "    \n",
        "    # output, probs = model(data)\n",
        "    # loss = loss_fn(probs, target)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # if batch_idx % 50 == 0:\n",
        "  print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t'.format(epoch, batch_idx * len(data), len(training_loader.dataset),100. * batch_idx / len(training_loader)))\n",
        "  print('\\nLoss: ',loss.item(),'\\n')\n",
        "  print('--------------------------------------------\\n')\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "hurKhxtioT67"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in validation_loader:\n",
        "      if True:\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "      data, target = Variable(data, volatile=True), Variable(target)\n",
        "\n",
        "      if True:\n",
        "        output, probs = model(data, target)\n",
        "        reconstruction_loss = F.mse_loss(output, data.view(-1, 784), size_average=False).item()\n",
        "        test_loss += loss_fn(probs, target, size_average=False).item()\n",
        "        test_loss += reconstruction_alpha * reconstruction_loss\n",
        "      else:\n",
        "        output, probs = model(data)\n",
        "        test_loss += loss_fn(probs, target, size_average=False).item()\n",
        "\n",
        "      pred = probs.data.max(1, keepdim=True)[1]  # get the index of the max probability\n",
        "      correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(validation_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "              test_loss, correct, len(validation_loader.dataset),\n",
        "              100. * correct / len(validation_loader.dataset)))\n",
        "    return test_loss"
      ],
      "metadata": {
        "id": "7hm_hvTdpLpv"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epoch=2\n",
        "for epoch in range(1, num_epoch + 1):\n",
        "  train(epoch)\n",
        "  test_loss = test()\n",
        "  scheduler.step(test_loss)\n",
        "  torch.save(model.state_dict(),\n",
        "                   '{:03d}_model_dict_{}.pth'.format(epoch, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OkL-jI4pUQH",
        "outputId": "e52f7247-cc8a-4a15-c795-a12afd5c98f6"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/CapsNet-pytorch/net.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  c = F.softmax(self.b)\n",
            "/content/CapsNet-pytorch/net.py:38: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  c = F.softmax(b_batch.view(-1, output_caps)).view(-1, input_caps, output_caps, 1)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [59990/60000 (100%)]\t\n",
            "\n",
            "Loss:  0.00014646285853814334 \n",
            "\n",
            "--------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0324, Accuracy: 9808/10000 (98%)\n",
            "\n",
            "Train Epoch: 2 [59990/60000 (100%)]\t\n",
            "\n",
            "Loss:  7.118638313841075e-05 \n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0297, Accuracy: 9859/10000 (99%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "\n",
        "index = random.randint(0, 1000 - 1)\n",
        "\n",
        "for i, data in enumerate(validation_loader):\n",
        "  # Every data instance is an input + label pair\n",
        "  if index==i:\n",
        "    inputs, labels = data\n",
        "          \n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Make predictions for this batch\n",
        "    outputs, probs = model(inputs, labels)\n",
        "\n",
        "    pred = probs.data.max(1, keepdim=True)[1].cpu()\n",
        "    \n",
        "    imshow(inputs[0])\n",
        "    print('labels: ',classes[labels[0]])\n",
        "    print('predicted: ',pred[0][0].numpy())\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "mZRSOGipxSnp",
        "outputId": "83250490-b594-4235-cb69-6d1d3779b151"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/CapsNet-pytorch/net.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  c = F.softmax(self.b)\n",
            "/content/CapsNet-pytorch/net.py:38: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  c = F.softmax(b_batch.view(-1, output_caps)).view(-1, input_caps, output_caps, 1)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:586: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels:  0\n",
            "predicted:  0\n"
          ]
        }
      ]
    }
  ]
}