{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "capsule.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPt07OYsqPrpzhD6wyF7BBs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paolo-peretti/conv/blob/main/capsule.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/paolo-peretti/conv\n",
        "import sys, os\n",
        "sys.path.append('/content')\n",
        "os.chdir('/content/conv/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu8h4aV6gyI_",
        "outputId": "0f1fc556-595a-4d35-b7bd-628f4cb019d9"
      },
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'conv' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torchvision.datasets import MNIST, CIFAR10\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "87g7dQwVlqgW"
      },
      "execution_count": 340,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from capsule_net import CapsNetWithReconstruction, CapsNet, ReconstructionNet, MarginLoss"
      ],
      "metadata": {
        "id": "UxZzveohlw5-"
      },
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Helper function for inline image display\n",
        "def imshow_MNIST(img):\n",
        "    img = img.cpu()\n",
        "    # img = img / 2 + 0.5     # unnormalize\n",
        "    # npimg = img.numpy()\n",
        "    plt.imshow(img.resize(28,28))\n",
        "    plt.show()\n",
        "\n",
        "def imshow_CIFAR10(img):\n",
        "    img = img.cpu()\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ZLnNf85O1Icz"
      },
      "execution_count": 342,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "def squash(x):\n",
        "  lengths2 = x.pow(2).sum(dim=2)\n",
        "  lengths = lengths2.sqrt()\n",
        "  x = x * (lengths2 / (1 + lengths2) / lengths).view(x.size(0), x.size(1), 1)\n",
        "  return x\n",
        "\n",
        "\n",
        "class AgreementRouting(nn.Module):\n",
        "  def __init__(self, input_caps, output_caps, n_iterations):\n",
        "      super(AgreementRouting, self).__init__()\n",
        "      self.n_iterations = n_iterations\n",
        "      self.b = nn.Parameter(torch.zeros((input_caps, output_caps)))\n",
        "\n",
        "  def forward(self, u_predict):\n",
        "      batch_size, input_caps, output_caps, output_dim = u_predict.size()\n",
        "\n",
        "      c = F.softmax(self.b)\n",
        "      s = (c.unsqueeze(2) * u_predict).sum(dim=1)\n",
        "      v = squash(s)\n",
        "\n",
        "      if self.n_iterations > 0:\n",
        "          b_batch = self.b.expand((batch_size, input_caps, output_caps))\n",
        "          for r in range(self.n_iterations):\n",
        "              v = v.unsqueeze(1)\n",
        "              b_batch = b_batch + (u_predict * v).sum(-1)\n",
        "\n",
        "              c = F.softmax(b_batch.view(-1, output_caps)).view(-1, input_caps, output_caps, 1)\n",
        "              s = (c * u_predict).sum(dim=1)\n",
        "              v = squash(s)\n",
        "\n",
        "      return v\n",
        "\n",
        "\n",
        "class CapsLayer(nn.Module):\n",
        "  def __init__(self, input_caps, input_dim, output_caps, output_dim, routing_module):\n",
        "      super(CapsLayer, self).__init__()\n",
        "      self.input_dim = input_dim\n",
        "      self.input_caps = input_caps\n",
        "      self.output_dim = output_dim\n",
        "      self.output_caps = output_caps\n",
        "      self.weights = nn.Parameter(torch.Tensor(input_caps, input_dim, output_caps * output_dim))\n",
        "      self.routing_module = routing_module\n",
        "      self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self):\n",
        "      stdv = 1. / math.sqrt(self.input_caps)\n",
        "      self.weights.data.uniform_(-stdv, stdv)\n",
        "\n",
        "  def forward(self, caps_output):\n",
        "      caps_output = caps_output.unsqueeze(2)\n",
        "      u_predict = caps_output.matmul(self.weights)\n",
        "      u_predict = u_predict.view(u_predict.size(0), self.input_caps, self.output_caps, self.output_dim)\n",
        "      v = self.routing_module(u_predict)\n",
        "      return v\n",
        "\n",
        "\n",
        "class PrimaryCapsLayer(nn.Module):\n",
        "  def __init__(self, input_channels, output_caps, output_dim, kernel_size, stride):\n",
        "      super(PrimaryCapsLayer, self).__init__()\n",
        "      self.conv = nn.Conv2d(input_channels, output_caps * output_dim, kernel_size=kernel_size, stride=stride)\n",
        "      self.input_channels = input_channels\n",
        "      self.output_caps = output_caps\n",
        "      self.output_dim = output_dim\n",
        "\n",
        "  def forward(self, input):\n",
        "      out = self.conv(input)\n",
        "      N, C, H, W = out.size()\n",
        "      out = out.view(N, self.output_caps, self.output_dim, H, W)\n",
        "\n",
        "      # will output N x OUT_CAPS x OUT_DIM\n",
        "      out = out.permute(0, 1, 3, 4, 2).contiguous()\n",
        "      out = out.view(out.size(0), -1, out.size(4))\n",
        "      out = squash(out)\n",
        "      return out\n",
        "\n",
        "\n",
        "class CapsNet(nn.Module):\n",
        "  def __init__(self, routing_iterations, input_channels=1, n_classes=10):\n",
        "      super(CapsNet, self).__init__()\n",
        "      self.conv1 = nn.Conv2d(input_channels, 256, kernel_size=9, stride=1)\n",
        "      self.primaryCaps = PrimaryCapsLayer(256, 32, 8, kernel_size=9, stride=2)  # outputs 6*6\n",
        "      if input_channels ==1:\n",
        "        self.num_primaryCaps = 32 * 6 * 6\n",
        "      elif input_channels == 3:\n",
        "        self.num_primaryCaps = 32 * 8 * 8\n",
        "\n",
        "      routing_module = AgreementRouting(self.num_primaryCaps, n_classes, routing_iterations)\n",
        "      self.digitCaps = CapsLayer(self.num_primaryCaps, 8, n_classes, 16, routing_module)\n",
        "\n",
        "  def forward(self, input):\n",
        "      \n",
        "      x = self.conv1(input)\n",
        "      \n",
        "      x = F.relu(x)\n",
        "  \n",
        "      x = self.primaryCaps(x)\n",
        "\n",
        "      x = self.digitCaps(x)\n",
        "  \n",
        "      probs = x.pow(2).sum(dim=2).sqrt()\n",
        "      return x, probs\n",
        "\n",
        "\n",
        "class ReconstructionNet(nn.Module):\n",
        "  def __init__(self, n_dim=16, n_classes=10):\n",
        "      super(ReconstructionNet, self).__init__()\n",
        "      self.fc1 = nn.Linear(n_dim * n_classes, 512)\n",
        "      self.fc2 = nn.Linear(512, 1024)\n",
        "      self.fc3 = nn.Linear(1024, 784)\n",
        "\n",
        "      self.fc4 = nn.Linear(784, 32*32*3)\n",
        "\n",
        "      self.n_dim = n_dim\n",
        "      self.n_classes = n_classes\n",
        "\n",
        "  def forward(self, x, target):\n",
        "      mask = Variable(torch.zeros((x.size()[0], self.n_classes)), requires_grad=False)\n",
        "      if next(self.parameters()).is_cuda:\n",
        "          mask = mask.cuda()\n",
        "      mask.scatter_(1, target.view(-1, 1), 1.)\n",
        "      mask = mask.unsqueeze(2)\n",
        "      x = x * mask\n",
        "      x = x.view(-1, self.n_dim * self.n_classes)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "\n",
        "      x = F.relu(self.fc3(x))\n",
        "\n",
        "      x = F.sigmoid(self.fc4(x))\n",
        "      return x\n",
        "\n",
        "\n",
        "class CapsNetWithReconstruction(nn.Module):\n",
        "  def __init__(self, capsnet, reconstruction_net):\n",
        "      super(CapsNetWithReconstruction, self).__init__()\n",
        "      self.capsnet = capsnet\n",
        "      self.reconstruction_net = reconstruction_net\n",
        "\n",
        "  def forward(self, x, target):\n",
        "      x, probs = self.capsnet(x)\n",
        "      reconstruction = self.reconstruction_net(x, target)\n",
        "      # print(x.shape)\n",
        "      return reconstruction, probs\n",
        "\n",
        "\n",
        "class MarginLoss(nn.Module):\n",
        "  def __init__(self, m_pos, m_neg, lambda_):\n",
        "      super(MarginLoss, self).__init__()\n",
        "      self.m_pos = m_pos\n",
        "      self.m_neg = m_neg\n",
        "      self.lambda_ = lambda_\n",
        "\n",
        "  def forward(self, lengths, targets, size_average=True):\n",
        "      t = torch.zeros(lengths.size()).long()\n",
        "      if targets.is_cuda:\n",
        "          t = t.cuda()\n",
        "      t = t.scatter_(1, targets.data.view(-1, 1), 1)\n",
        "      targets = Variable(t)\n",
        "      losses = targets.float() * F.relu(self.m_pos - lengths).pow(2) + \\\n",
        "                self.lambda_ * (1. - targets.float()) * F.relu(lengths - self.m_neg).pow(2)\n",
        "      return losses.mean() if size_average else losses.sum()"
      ],
      "metadata": {
        "id": "BhbPxeECee24"
      },
      "execution_count": 343,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "capsnet = CapsNet(3, 3, 10)\n",
        "reconstructionnet = ReconstructionNet(16, 10)\n",
        "model = CapsNetWithReconstruction(capsnet, reconstructionnet)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQzh2RhIl08d",
        "outputId": "14ad8abf-5d82-4ced-a69e-fb1613552b3f"
      },
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CapsNetWithReconstruction(\n",
              "  (capsnet): CapsNet(\n",
              "    (conv1): Conv2d(3, 256, kernel_size=(9, 9), stride=(1, 1))\n",
              "    (primaryCaps): PrimaryCapsLayer(\n",
              "      (conv): Conv2d(256, 256, kernel_size=(9, 9), stride=(2, 2))\n",
              "    )\n",
              "    (digitCaps): CapsLayer(\n",
              "      (routing_module): AgreementRouting()\n",
              "    )\n",
              "  )\n",
              "  (reconstruction_net): ReconstructionNet(\n",
              "    (fc1): Linear(in_features=160, out_features=512, bias=True)\n",
              "    (fc2): Linear(in_features=512, out_features=1024, bias=True)\n",
              "    (fc3): Linear(in_features=1024, out_features=784, bias=True)\n",
              "    (fc4): Linear(in_features=784, out_features=3072, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 344
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "# PyTorch TensorBoard support\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "\n",
        "stats = ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "transform = transforms.Compose(\n",
        "    [transforms.RandomCrop(32, padding=4, padding_mode='reflect'), \n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(*stats,inplace=True)])\n",
        "\n",
        "\n",
        "# Create datasets for training & validation, download if necessary\n",
        "# # MNIST\n",
        "\n",
        "# training_set = MNIST('./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "# validation_set = MNIST('./data', train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "# # CIFAR10\n",
        "training_set = torchvision.datasets.CIFAR10('./data', train=True, transform=transform, download=True)\n",
        "validation_set = torchvision.datasets.CIFAR10('./data', train=False, transform=transform, download=True)\n",
        "\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "\n",
        "# Create data loaders for our datasets; shuffle for training, not for validation\n",
        "training_loader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "\n",
        "# Class labels\n",
        "classes_MNIST = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
        "classes_CIFAR10 = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "        'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "classes = classes_CIFAR10\n",
        "# Report split sizes\n",
        "print('Training set has {} instances'.format(len(training_set)))\n",
        "print('Validation set has {} instances'.format(len(validation_set)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmAiKDdOprIB",
        "outputId": "4ce6fbd4-ea64-48bf-f115-564feba941dc"
      },
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training set has 50000 instances\n",
            "Validation set has 10000 instances\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import argparse\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "OLlul-HTnElD"
      },
      "execution_count": 346,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=15, min_lr=1e-6)\n",
        "loss_fn = MarginLoss(0.9, 0.1, 0.5)\n",
        "reconstruction_alpha=0.0005"
      ],
      "metadata": {
        "id": "DFrhWur8nfjF"
      },
      "execution_count": 347,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(training_loader):\n",
        "\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    data, target = Variable(data), Variable(target, requires_grad=False)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # with reconstruction\n",
        "    output, probs = model(data, target)\n",
        "    # print(output.shape, data.shape)\n",
        "    reconstruction_loss = F.mse_loss(output, data.view(-1, 32*32*3)) # , data.view(-1, 784)\n",
        "    margin_loss = loss_fn(probs, target)\n",
        "    loss = reconstruction_alpha * reconstruction_loss + margin_loss\n",
        "    \n",
        "    # output, probs = model(data)\n",
        "    # loss = loss_fn(probs, target)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # if batch_idx % 50 == 0:\n",
        "  print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t'.format(epoch, batch_idx * len(data), len(training_loader.dataset),100. * batch_idx / len(training_loader)))\n",
        "  print('\\nLoss: ',loss.item(),'\\n')\n",
        "  print('--------------------------------------------\\n')\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "hurKhxtioT67"
      },
      "execution_count": 348,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in validation_loader:\n",
        "      if True:\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "      data, target = Variable(data, volatile=True), Variable(target)\n",
        "\n",
        "      if True:\n",
        "        output, probs = model(data, target)\n",
        "        reconstruction_loss = F.mse_loss(output, data.view(-1, 32*32*3), size_average=False).item() #784\n",
        "        test_loss += loss_fn(probs, target, size_average=False).item()\n",
        "        test_loss += reconstruction_alpha * reconstruction_loss\n",
        "      else:\n",
        "        output, probs = model(data)\n",
        "        test_loss += loss_fn(probs, target, size_average=False).item()\n",
        "\n",
        "      pred = probs.data.max(1, keepdim=True)[1]  # get the index of the max probability\n",
        "      correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(validation_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "              test_loss, correct, len(validation_loader.dataset),\n",
        "              100. * correct / len(validation_loader.dataset)))\n",
        "    return test_loss"
      ],
      "metadata": {
        "id": "7hm_hvTdpLpv"
      },
      "execution_count": 349,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epoch=2\n",
        "for epoch in range(1, num_epoch + 1):\n",
        "  train(epoch)\n",
        "  test_loss = test()\n",
        "  scheduler.step(test_loss)\n",
        "  torch.save(model.state_dict(),\n",
        "                   '{:03d}_model_dict_{}.pth'.format(epoch, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OkL-jI4pUQH",
        "outputId": "39dd4b23-e3e5-45c3-b8ef-e0da83eb92ac"
      },
      "execution_count": 350,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [49990/50000 (100%)]\t\n",
            "\n",
            "Loss:  0.040028803050518036 \n",
            "\n",
            "--------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.8022, Accuracy: 4005/10000 (40%)\n",
            "\n",
            "Train Epoch: 2 [49990/50000 (100%)]\t\n",
            "\n",
            "Loss:  0.025138942524790764 \n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.7520, Accuracy: 4764/10000 (48%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "\n",
        "index = random.randint(0, 1000 - 1)\n",
        "\n",
        "for i, data in enumerate(validation_loader):\n",
        "  # Every data instance is an input + label pair\n",
        "  if index==i:\n",
        "    inputs, labels = data\n",
        "          \n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Make predictions for this batch\n",
        "    outputs, probs = model(inputs, labels)\n",
        "    \n",
        "    pred = probs.data.max(1, keepdim=True)[1].cpu()\n",
        "    \n",
        "    imshow_CIFAR10(inputs[0])\n",
        "    \n",
        "    print('labels: ',classes[labels[0]])\n",
        "    # CIFAR10\n",
        "    print('predicted: ',classes[pred[0][0].numpy()])\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "mZRSOGipxSnp",
        "outputId": "2e74b443-0663-4931-93ca-886ae8dfcd4c"
      },
      "execution_count": 357,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels:  airplane\n",
            "predicted:  airplane\n"
          ]
        }
      ]
    }
  ]
}