{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "capsule.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2JGVxywNGZKuW9IyOaVsz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paolo-peretti/conv/blob/main/capsule.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/paolo-peretti/conv\n",
        "import sys, os\n",
        "sys.path.append('/content')\n",
        "os.chdir('/content/conv/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu8h4aV6gyI_",
        "outputId": "0f1fc556-595a-4d35-b7bd-628f4cb019d9"
      },
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'conv' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torchvision.datasets import MNIST, CIFAR10\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "87g7dQwVlqgW"
      },
      "execution_count": 340,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from capsule_net import CapsNetWithReconstruction, CapsNet, ReconstructionNet, MarginLoss"
      ],
      "metadata": {
        "id": "UxZzveohlw5-"
      },
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Helper function for inline image display\n",
        "def imshow_MNIST(img):\n",
        "    img = img.cpu()\n",
        "    # img = img / 2 + 0.5     # unnormalize\n",
        "    # npimg = img.numpy()\n",
        "    plt.imshow(img.resize(28,28))\n",
        "    plt.show()\n",
        "\n",
        "def imshow_CIFAR10(img):\n",
        "    img = img.cpu()\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ZLnNf85O1Icz"
      },
      "execution_count": 342,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "def squash(x):\n",
        "  lengths2 = x.pow(2).sum(dim=2)\n",
        "  lengths = lengths2.sqrt()\n",
        "  x = x * (lengths2 / (1 + lengths2) / lengths).view(x.size(0), x.size(1), 1)\n",
        "  return x\n",
        "\n",
        "\n",
        "class AgreementRouting(nn.Module):\n",
        "  def __init__(self, input_caps, output_caps, n_iterations):\n",
        "      super(AgreementRouting, self).__init__()\n",
        "      self.n_iterations = n_iterations\n",
        "      self.b = nn.Parameter(torch.zeros((input_caps, output_caps)))\n",
        "\n",
        "  def forward(self, u_predict):\n",
        "      batch_size, input_caps, output_caps, output_dim = u_predict.size()\n",
        "\n",
        "      c = F.softmax(self.b)\n",
        "      s = (c.unsqueeze(2) * u_predict).sum(dim=1)\n",
        "      v = squash(s)\n",
        "\n",
        "      if self.n_iterations > 0:\n",
        "          b_batch = self.b.expand((batch_size, input_caps, output_caps))\n",
        "          for r in range(self.n_iterations):\n",
        "              v = v.unsqueeze(1)\n",
        "              b_batch = b_batch + (u_predict * v).sum(-1)\n",
        "\n",
        "              c = F.softmax(b_batch.view(-1, output_caps)).view(-1, input_caps, output_caps, 1)\n",
        "              s = (c * u_predict).sum(dim=1)\n",
        "              v = squash(s)\n",
        "\n",
        "      return v\n",
        "\n",
        "\n",
        "class CapsLayer(nn.Module):\n",
        "  def __init__(self, input_caps, input_dim, output_caps, output_dim, routing_module):\n",
        "      super(CapsLayer, self).__init__()\n",
        "      self.input_dim = input_dim\n",
        "      self.input_caps = input_caps\n",
        "      self.output_dim = output_dim\n",
        "      self.output_caps = output_caps\n",
        "      self.weights = nn.Parameter(torch.Tensor(input_caps, input_dim, output_caps * output_dim))\n",
        "      self.routing_module = routing_module\n",
        "      self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self):\n",
        "      stdv = 1. / math.sqrt(self.input_caps)\n",
        "      self.weights.data.uniform_(-stdv, stdv)\n",
        "\n",
        "  def forward(self, caps_output):\n",
        "      caps_output = caps_output.unsqueeze(2)\n",
        "      u_predict = caps_output.matmul(self.weights)\n",
        "      u_predict = u_predict.view(u_predict.size(0), self.input_caps, self.output_caps, self.output_dim)\n",
        "      v = self.routing_module(u_predict)\n",
        "      return v\n",
        "\n",
        "\n",
        "class PrimaryCapsLayer(nn.Module):\n",
        "  def __init__(self, input_channels, output_caps, output_dim, kernel_size, stride):\n",
        "      super(PrimaryCapsLayer, self).__init__()\n",
        "      self.conv = nn.Conv2d(input_channels, output_caps * output_dim, kernel_size=kernel_size, stride=stride)\n",
        "      self.input_channels = input_channels\n",
        "      self.output_caps = output_caps\n",
        "      self.output_dim = output_dim\n",
        "\n",
        "  def forward(self, input):\n",
        "      out = self.conv(input)\n",
        "      N, C, H, W = out.size()\n",
        "      out = out.view(N, self.output_caps, self.output_dim, H, W)\n",
        "\n",
        "      # will output N x OUT_CAPS x OUT_DIM\n",
        "      out = out.permute(0, 1, 3, 4, 2).contiguous()\n",
        "      out = out.view(out.size(0), -1, out.size(4))\n",
        "      out = squash(out)\n",
        "      return out\n",
        "\n",
        "\n",
        "class CapsNet(nn.Module):\n",
        "  def __init__(self, routing_iterations, input_channels=1, n_classes=10):\n",
        "      super(CapsNet, self).__init__()\n",
        "      self.conv1 = nn.Conv2d(input_channels, 256, kernel_size=9, stride=1)\n",
        "      self.primaryCaps = PrimaryCapsLayer(256, 32, 8, kernel_size=9, stride=2)  # outputs 6*6\n",
        "      if input_channels ==1:\n",
        "        self.num_primaryCaps = 32 * 6 * 6\n",
        "      elif input_channels == 3:\n",
        "        self.num_primaryCaps = 32 * 8 * 8\n",
        "\n",
        "      routing_module = AgreementRouting(self.num_primaryCaps, n_classes, routing_iterations)\n",
        "      self.digitCaps = CapsLayer(self.num_primaryCaps, 8, n_classes, 16, routing_module)\n",
        "\n",
        "  def forward(self, input):\n",
        "      \n",
        "      x = self.conv1(input)\n",
        "      \n",
        "      x = F.relu(x)\n",
        "  \n",
        "      x = self.primaryCaps(x)\n",
        "\n",
        "      x = self.digitCaps(x)\n",
        "  \n",
        "      probs = x.pow(2).sum(dim=2).sqrt()\n",
        "      return x, probs\n",
        "\n",
        "\n",
        "class ReconstructionNet(nn.Module):\n",
        "  def __init__(self, n_dim=16, n_classes=10):\n",
        "      super(ReconstructionNet, self).__init__()\n",
        "      self.fc1 = nn.Linear(n_dim * n_classes, 512)\n",
        "      self.fc2 = nn.Linear(512, 1024)\n",
        "      self.fc3 = nn.Linear(1024, 784)\n",
        "\n",
        "      self.fc4 = nn.Linear(784, 32*32*3)\n",
        "\n",
        "      self.n_dim = n_dim\n",
        "      self.n_classes = n_classes\n",
        "\n",
        "  def forward(self, x, target):\n",
        "      mask = Variable(torch.zeros((x.size()[0], self.n_classes)), requires_grad=False)\n",
        "      if next(self.parameters()).is_cuda:\n",
        "          mask = mask.cuda()\n",
        "      mask.scatter_(1, target.view(-1, 1), 1.)\n",
        "      mask = mask.unsqueeze(2)\n",
        "      x = x * mask\n",
        "      x = x.view(-1, self.n_dim * self.n_classes)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "\n",
        "      x = F.relu(self.fc3(x))\n",
        "\n",
        "      x = F.sigmoid(self.fc4(x))\n",
        "      return x\n",
        "\n",
        "\n",
        "class CapsNetWithReconstruction(nn.Module):\n",
        "  def __init__(self, capsnet, reconstruction_net):\n",
        "      super(CapsNetWithReconstruction, self).__init__()\n",
        "      self.capsnet = capsnet\n",
        "      self.reconstruction_net = reconstruction_net\n",
        "\n",
        "  def forward(self, x, target):\n",
        "      x, probs = self.capsnet(x)\n",
        "      reconstruction = self.reconstruction_net(x, target)\n",
        "      # print(x.shape)\n",
        "      return reconstruction, probs\n",
        "\n",
        "\n",
        "class MarginLoss(nn.Module):\n",
        "  def __init__(self, m_pos, m_neg, lambda_):\n",
        "      super(MarginLoss, self).__init__()\n",
        "      self.m_pos = m_pos\n",
        "      self.m_neg = m_neg\n",
        "      self.lambda_ = lambda_\n",
        "\n",
        "  def forward(self, lengths, targets, size_average=True):\n",
        "      t = torch.zeros(lengths.size()).long()\n",
        "      if targets.is_cuda:\n",
        "          t = t.cuda()\n",
        "      t = t.scatter_(1, targets.data.view(-1, 1), 1)\n",
        "      targets = Variable(t)\n",
        "      losses = targets.float() * F.relu(self.m_pos - lengths).pow(2) + \\\n",
        "                self.lambda_ * (1. - targets.float()) * F.relu(lengths - self.m_neg).pow(2)\n",
        "      return losses.mean() if size_average else losses.sum()"
      ],
      "metadata": {
        "id": "BhbPxeECee24"
      },
      "execution_count": 343,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "capsnet = CapsNet(3, 3, 10)\n",
        "reconstructionnet = ReconstructionNet(16, 10)\n",
        "model = CapsNetWithReconstruction(capsnet, reconstructionnet)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQzh2RhIl08d",
        "outputId": "14ad8abf-5d82-4ced-a69e-fb1613552b3f"
      },
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CapsNetWithReconstruction(\n",
              "  (capsnet): CapsNet(\n",
              "    (conv1): Conv2d(3, 256, kernel_size=(9, 9), stride=(1, 1))\n",
              "    (primaryCaps): PrimaryCapsLayer(\n",
              "      (conv): Conv2d(256, 256, kernel_size=(9, 9), stride=(2, 2))\n",
              "    )\n",
              "    (digitCaps): CapsLayer(\n",
              "      (routing_module): AgreementRouting()\n",
              "    )\n",
              "  )\n",
              "  (reconstruction_net): ReconstructionNet(\n",
              "    (fc1): Linear(in_features=160, out_features=512, bias=True)\n",
              "    (fc2): Linear(in_features=512, out_features=1024, bias=True)\n",
              "    (fc3): Linear(in_features=1024, out_features=784, bias=True)\n",
              "    (fc4): Linear(in_features=784, out_features=3072, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 344
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "# PyTorch TensorBoard support\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "\n",
        "stats = ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "transform = transforms.Compose(\n",
        "    [transforms.RandomCrop(32, padding=4, padding_mode='reflect'), \n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(*stats,inplace=True)])\n",
        "\n",
        "\n",
        "# Create datasets for training & validation, download if necessary\n",
        "# # MNIST\n",
        "\n",
        "# training_set = MNIST('./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "# validation_set = MNIST('./data', train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "# # CIFAR10\n",
        "training_set = torchvision.datasets.CIFAR10('./data', train=True, transform=transform, download=True)\n",
        "validation_set = torchvision.datasets.CIFAR10('./data', train=False, transform=transform, download=True)\n",
        "\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "\n",
        "# Create data loaders for our datasets; shuffle for training, not for validation\n",
        "training_loader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "\n",
        "# Class labels\n",
        "classes_MNIST = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
        "classes_CIFAR10 = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "        'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "classes = classes_CIFAR10\n",
        "# Report split sizes\n",
        "print('Training set has {} instances'.format(len(training_set)))\n",
        "print('Validation set has {} instances'.format(len(validation_set)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmAiKDdOprIB",
        "outputId": "4ce6fbd4-ea64-48bf-f115-564feba941dc"
      },
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training set has 50000 instances\n",
            "Validation set has 10000 instances\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import argparse\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "OLlul-HTnElD"
      },
      "execution_count": 346,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=15, min_lr=1e-6)\n",
        "loss_fn = MarginLoss(0.9, 0.1, 0.5)\n",
        "reconstruction_alpha=0.0005"
      ],
      "metadata": {
        "id": "DFrhWur8nfjF"
      },
      "execution_count": 347,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(training_loader):\n",
        "\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    data, target = Variable(data), Variable(target, requires_grad=False)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # with reconstruction\n",
        "    output, probs = model(data, target)\n",
        "    # print(output.shape, data.shape)\n",
        "    reconstruction_loss = F.mse_loss(output, data.view(-1, 32*32*3)) # , data.view(-1, 784)\n",
        "    margin_loss = loss_fn(probs, target)\n",
        "    loss = reconstruction_alpha * reconstruction_loss + margin_loss\n",
        "    \n",
        "    # output, probs = model(data)\n",
        "    # loss = loss_fn(probs, target)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # if batch_idx % 50 == 0:\n",
        "  print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t'.format(epoch, batch_idx * len(data), len(training_loader.dataset),100. * batch_idx / len(training_loader)))\n",
        "  print('\\nLoss: ',loss.item(),'\\n')\n",
        "  print('--------------------------------------------\\n')\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "hurKhxtioT67"
      },
      "execution_count": 348,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in validation_loader:\n",
        "      if True:\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "      data, target = Variable(data, volatile=True), Variable(target)\n",
        "\n",
        "      if True:\n",
        "        output, probs = model(data, target)\n",
        "        reconstruction_loss = F.mse_loss(output, data.view(-1, 32*32*3), size_average=False).item() #784\n",
        "        test_loss += loss_fn(probs, target, size_average=False).item()\n",
        "        test_loss += reconstruction_alpha * reconstruction_loss\n",
        "      else:\n",
        "        output, probs = model(data)\n",
        "        test_loss += loss_fn(probs, target, size_average=False).item()\n",
        "\n",
        "      pred = probs.data.max(1, keepdim=True)[1]  # get the index of the max probability\n",
        "      correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(validation_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "              test_loss, correct, len(validation_loader.dataset),\n",
        "              100. * correct / len(validation_loader.dataset)))\n",
        "    return test_loss"
      ],
      "metadata": {
        "id": "7hm_hvTdpLpv"
      },
      "execution_count": 349,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epoch=2\n",
        "for epoch in range(1, num_epoch + 1):\n",
        "  train(epoch)\n",
        "  test_loss = test()\n",
        "  scheduler.step(test_loss)\n",
        "  torch.save(model.state_dict(),\n",
        "                   '{:03d}_model_dict_{}.pth'.format(epoch, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OkL-jI4pUQH",
        "outputId": "39dd4b23-e3e5-45c3-b8ef-e0da83eb92ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "\n",
        "index = random.randint(0, 1000 - 1)\n",
        "\n",
        "for i, data in enumerate(validation_loader):\n",
        "  # Every data instance is an input + label pair\n",
        "  if index==i:\n",
        "    inputs, labels = data\n",
        "          \n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Make predictions for this batch\n",
        "    outputs, probs = model(inputs, labels)\n",
        "\n",
        "    pred = probs.data.max(1, keepdim=True)[1].cpu()\n",
        "    \n",
        "    imshow_CIFAR10(inputs[0])\n",
        "    print('labels: ',classes[labels[0]])\n",
        "    print('predicted: ',pred[0][0].numpy())\n",
        "    break"
      ],
      "metadata": {
        "id": "mZRSOGipxSnp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}