{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paolo-peretti/conv/blob/main/conv1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "4KoLO7ooSTO7"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azkTh_eCTQsj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAPCP4B7VQ_H",
        "outputId": "80cd449a-ae99-4d06-96a5-60ff061864b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqsvjRw6Wlsu"
      },
      "source": [
        "Preproccessing on dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_RH0DvcWr9K",
        "outputId": "6c5e1e25-3b53-4770-afe1-2b4c02501b82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training set has 50000 instances\n",
            "Validation set has 10000 instances\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "# PyTorch TensorBoard support\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "\n",
        "stats = ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "transform = transforms.Compose(\n",
        "    [transforms.RandomCrop(32, padding=4, padding_mode='reflect'), \n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(*stats,inplace=True)])\n",
        "\n",
        "\n",
        "# Create datasets for training & validation, download if necessary\n",
        "training_set = torchvision.datasets.CIFAR10('./data', train=True, transform=transform, download=True)\n",
        "validation_set = torchvision.datasets.CIFAR10('./data', train=False, transform=transform, download=True)\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "\n",
        "# Create data loaders for our datasets; shuffle for training, not for validation\n",
        "training_loader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "\n",
        "# Class labels\n",
        "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "        'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Report split sizes\n",
        "print('Training set has {} instances'.format(len(training_set)))\n",
        "print('Validation set has {} instances'.format(len(validation_set)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TLqzeYManlC"
      },
      "source": [
        "I want see a grid of images of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "cttIUs4gZ_9z",
        "outputId": "cbe6fe1f-dd21-4bb7-d209-b0f0d858426d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "horse\n",
            ".............................................\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Helper function for inline image display\n",
        "def imshow(img):\n",
        "    img = img.cpu()\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(training_loader)\n",
        "images, labels = dataiter.next()\n",
        "# print(len(images), len(labels))\n",
        "print(classes[labels[0]])\n",
        "print('.............................................\\n')\n",
        "imshow(images[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMsV9P1_STO9"
      },
      "source": [
        "\n",
        "\n",
        "Building The Model\n",
        "============================\n",
        "\n",
        "One important behavior of ``torch.nn.Module`` is registering parameters.\n",
        "If a particular ``Module`` subclass has learning weights, these weights\n",
        "are expressed as instances of ``torch.nn.Parameter``. The ``Parameter``\n",
        "class is a subclass of ``torch.Tensor``, with the special behavior that\n",
        "when they are assigned as attributes of a ``Module``, they are added to\n",
        "the list of that modules parameters. These parameters may be accessed\n",
        "through the ``parameters()`` method on the ``Module`` class.\n",
        "\n",
        "As a simple example, here’s a very simple model with two linear layers\n",
        "and an activation function. We’ll create an instance of it and ask it to\n",
        "report on its parameters:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWtLhhtDTdv-",
        "outputId": "515d9bf8-ca77-4e6e-adf9-cd422f7abb99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model:\n",
            "MyModel(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (linear1): Linear(in_features=16384, out_features=540, bias=True)\n",
            "  (linear2): Linear(in_features=540, out_features=146, bias=True)\n",
            "  (linear3): Linear(in_features=146, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "class MyModel(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        \n",
        "        # CV\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=3,out_channels=6,kernel_size=5, padding=2,stride=1)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(6)\n",
        "        \n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=6,out_channels=16,kernel_size=3, padding=1,stride=1)\n",
        "        self.bn2 = torch.nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv3 = torch.nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3, padding=1,stride=1)\n",
        "        self.bn3 = torch.nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv4 = torch.nn.Conv2d(in_channels=32,out_channels=64,kernel_size=2, padding=1,stride=1)\n",
        "        self.bn4 = torch.nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
        "\n",
        "\n",
        "        # FC\n",
        "        self.linear1 = torch.nn.Linear(64*16*16, 540)\n",
        "        self.linear2 = torch.nn.Linear(540, 146)\n",
        "        self.linear3 = torch.nn.Linear(146, 10)\n",
        "\n",
        "        # Define proportion or neurons to dropout\n",
        "        self.dropout = torch.nn.Dropout(0.25)\n",
        "\n",
        "\n",
        "        # self.softmax = torch.nn.Softmax(dim=10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn2(x)\n",
        "        # print(x.shape)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # print(x.shape)\n",
        "        # x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = x.view(-1, 64*16*16)\n",
        "        # print(x.shape)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear3(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "my_model = MyModel()\n",
        "my_model = my_model.to(device)\n",
        "\n",
        "print('The model:')\n",
        "print(my_model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jp3SazGknWr"
      },
      "source": [
        "\n",
        "Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(in_channels, out_channels, pool=False):\n",
        "\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
        "              nn.BatchNorm2d(out_channels), \n",
        "              nn.ReLU(inplace=True)]\n",
        "    if pool: layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResNet9(torch.nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Conv. Layers\n",
        "        self.conv1 = conv_block(in_channels, 64)\n",
        "        self.conv2 = conv_block(64, 128, pool=True)\n",
        "        self.conv3 = conv_block(128, 128)\n",
        "        self.conv4 = conv_block(128, 256, pool=True)\n",
        "        self.conv5 = conv_block(256, 512, pool=True)\n",
        "        self.conv6 = conv_block(512, 512)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        \n",
        "        # FN\n",
        "        self.fn1 = nn.Sequential(nn.MaxPool2d(4), \n",
        "                                        nn.Flatten(), \n",
        "                                        nn.Linear(512, 256))\n",
        "        \n",
        "        self.fn2 = nn.Linear(256, num_classes)\n",
        "        \n",
        "        self.classifier = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.conv5(out)\n",
        "        out = self.conv6(out)\n",
        "\n",
        "        out = self.fn1(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fn2(out)\n",
        "        \n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "resnet = ResNet9(3,10)\n",
        "resnet = resnet.to(device)\n",
        "print(resnet)"
      ],
      "metadata": {
        "id": "4dCd5UG5bxIl",
        "outputId": "a3bda4fe-a341-437e-9821-2c0387179fc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet9(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv5): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv6): Sequential(\n",
            "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            "  (fn1): Sequential(\n",
            "    (0): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
            "    (1): Flatten(start_dim=1, end_dim=-1)\n",
            "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  )\n",
            "  (fn2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (classifier): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet"
      ],
      "metadata": {
        "id": "qVDI82DEc-10"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "5HzXTDFzkpa8"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEhQZ87mk3yj"
      },
      "source": [
        "The Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "metadata": {
        "id": "mX-COhixzccT"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, validation_loader):\n",
        "\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      model.eval()\n",
        "\n",
        "      running_vloss = 0.0\n",
        "      running_vacc = 0.0\n",
        "\n",
        "      for i, vdata in enumerate(validation_loader):\n",
        "\n",
        "          vinputs, vlabels = vdata\n",
        "\n",
        "          vinputs = vinputs.to(device)\n",
        "          vlabels = vlabels.to(device)\n",
        "          \n",
        "          voutputs = model(vinputs)\n",
        "          \n",
        "\n",
        "          running_vloss += loss_fn(voutputs, vlabels).item()\n",
        "        \n",
        "          running_vacc += accuracy(voutputs, vlabels).item()\n",
        "\n",
        "      avg_vloss = running_vloss / (i + 1)\n",
        "      avg_vaccuracy = running_vacc / (i + 1)\n",
        "\n",
        "      print('  avg_vloss: {}'.format(avg_vloss))\n",
        "      print('  avg_vaccuracy: {}'.format(avg_vaccuracy))\n",
        "\n",
        "      return avg_vloss, avg_vaccuracy"
      ],
      "metadata": {
        "id": "WcmgIXQSyB1q"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "KG70iA5yk4yO"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(epoch_index):\n",
        "\n",
        "    model.train()\n",
        "  \n",
        "    running_loss = 0.\n",
        "    running_accuracy = 0.\n",
        "\n",
        " \n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(training_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "        \n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "\n",
        "        running_accuracy += accuracy(outputs,labels).item()\n",
        "\n",
        "\n",
        "        if i % 1000 == 999:\n",
        "\n",
        "            last_loss = running_loss / 1000\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            last_accuracy = running_accuracy / 1000\n",
        "            print('  batch {} accuracy: {}'.format(i + 1, last_accuracy))\n",
        "            \n",
        "            running_loss = 0.\n",
        "            running_accuracy = 0.\n",
        "\n",
        "            print('-----------------------------------------------------------------------')\n",
        "  \n",
        "\n",
        "      \n",
        "    # last_loss = running_loss / (i + 1) # loss per batch\n",
        "    # last_accuracy = running_accuracy / (i + 1)\n",
        "    # print('  loss: {}'.format(last_loss))\n",
        "    # print('  accuracy: {}'.format(last_accuracy))\n",
        "    \n",
        "      \n",
        "\n",
        "    return last_loss, last_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "lCTEK5RkBAyy"
      },
      "outputs": [],
      "source": [
        "def train_data(EPOCHS):\n",
        "\n",
        "  patience = 2\n",
        "  best_vloss = 1_000_000.\n",
        "  trigger_times = 0\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "\n",
        "      print('\\n\\nEPOCH {}:'.format(epoch + 1))\n",
        "\n",
        "      model.requires_grad_(True)\n",
        "      \n",
        "      avg_loss, avg_accuracy = train_one_epoch(epoch)\n",
        "\n",
        "      model.requires_grad_(False)\n",
        "\n",
        "      vloss, vaccuracy = evaluate(model, validation_loader)\n",
        "      \n",
        "\n",
        "      # Early stopping\n",
        "        \n",
        "      if avg_loss > best_vloss:\n",
        "          trigger_times += 1\n",
        "          print('Trigger Times:', trigger_times)\n",
        "\n",
        "          if trigger_times >= patience:\n",
        "              print('Early stopping!\\nStart to test process.')\n",
        "              return model\n",
        "\n",
        "          else:\n",
        "              print('trigger times: 0')\n",
        "              trigger_times = 0\n",
        "\n",
        "      best_vloss = avg_loss\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = train_data(10)\n",
        "\n",
        "torch.save(model.state_dict(), 'cifar10_model.pth')\n"
      ],
      "metadata": {
        "id": "rn_KRYbojCJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2e5c600-d7a9-42d1-806c-3c83551e542e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "EPOCH 1:\n",
            "  batch 1000 loss: 2.0624893379211424\n",
            "  batch 1000 accuracy: 0.238125\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 1.7837999408245087\n",
            "  batch 2000 accuracy: 0.33175\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 1.6442340562939644\n",
            "  batch 3000 accuracy: 0.400375\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 1.4923721429407597\n",
            "  batch 4000 accuracy: 0.461\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 1.3917295094132422\n",
            "  batch 5000 accuracy: 0.495875\n",
            "-----------------------------------------------------------------------\n",
            "  batch 6000 loss: 1.289499269962311\n",
            "  batch 6000 accuracy: 0.54925\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 1.1002121130108833\n",
            "  avg_vaccuracy: 0.6051\n",
            "\n",
            "\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 1.176365318313241\n",
            "  batch 1000 accuracy: 0.584125\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 1.1487064332664012\n",
            "  batch 2000 accuracy: 0.6005\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 1.0669975511431693\n",
            "  batch 3000 accuracy: 0.627125\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 1.0150025496780872\n",
            "  batch 4000 accuracy: 0.645875\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.9816565259546042\n",
            "  batch 5000 accuracy: 0.661625\n",
            "-----------------------------------------------------------------------\n",
            "  batch 6000 loss: 0.9381502646952867\n",
            "  batch 6000 accuracy: 0.67925\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.8433491748362779\n",
            "  avg_vaccuracy: 0.702\n",
            "\n",
            "\n",
            "EPOCH 3:\n",
            "  batch 1000 loss: 0.8697428554520011\n",
            "  batch 1000 accuracy: 0.69775\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.8603982843384147\n",
            "  batch 2000 accuracy: 0.701375\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.8524059382081032\n",
            "  batch 3000 accuracy: 0.711375\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.8115796975120902\n",
            "  batch 4000 accuracy: 0.718125\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.8288038799464703\n",
            "  batch 5000 accuracy: 0.71675\n",
            "-----------------------------------------------------------------------\n",
            "  batch 6000 loss: 0.7915284110233187\n",
            "  batch 6000 accuracy: 0.72775\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.8031853233814239\n",
            "  avg_vaccuracy: 0.7229\n",
            "\n",
            "\n",
            "EPOCH 4:\n",
            "  batch 1000 loss: 0.7530498675853013\n",
            "  batch 1000 accuracy: 0.742875\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.7367851141579449\n",
            "  batch 2000 accuracy: 0.747125\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.7432715438902379\n",
            "  batch 3000 accuracy: 0.7445\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.7387639022599906\n",
            "  batch 4000 accuracy: 0.744\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.7474221605993807\n",
            "  batch 5000 accuracy: 0.743\n",
            "-----------------------------------------------------------------------\n",
            "  batch 6000 loss: 0.7220832251161337\n",
            "  batch 6000 accuracy: 0.755125\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.7452081722468138\n",
            "  avg_vaccuracy: 0.7495\n",
            "\n",
            "\n",
            "EPOCH 5:\n",
            "  batch 1000 loss: 0.6909672990255058\n",
            "  batch 1000 accuracy: 0.7635\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.6910332094877958\n",
            "  batch 2000 accuracy: 0.766375\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.6842038699612022\n",
            "  batch 3000 accuracy: 0.76375\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.6652104768790305\n",
            "  batch 4000 accuracy: 0.777625\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.6606386410724372\n",
            "  batch 5000 accuracy: 0.777125\n",
            "-----------------------------------------------------------------------\n",
            "  batch 6000 loss: 0.6525804401189089\n",
            "  batch 6000 accuracy: 0.78075\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.6472159236520528\n",
            "  avg_vaccuracy: 0.7774\n",
            "\n",
            "\n",
            "EPOCH 6:\n",
            "  batch 1000 loss: 0.6307514356598258\n",
            "  batch 1000 accuracy: 0.789\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.6459189382977784\n",
            "  batch 2000 accuracy: 0.78175\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.627415720500052\n",
            "  batch 3000 accuracy: 0.78975\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.6503920006453991\n",
            "  batch 4000 accuracy: 0.781625\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.6325013585500419\n",
            "  batch 5000 accuracy: 0.78675\n",
            "-----------------------------------------------------------------------\n",
            "  batch 6000 loss: 0.6371798993907869\n",
            "  batch 6000 accuracy: 0.78725\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.5919405958771705\n",
            "  avg_vaccuracy: 0.8015\n",
            "\n",
            "\n",
            "EPOCH 7:\n",
            "  batch 1000 loss: 0.5935201163310557\n",
            "  batch 1000 accuracy: 0.79975\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.5997987638451159\n",
            "  batch 2000 accuracy: 0.797\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.6105970319081098\n",
            "  batch 3000 accuracy: 0.7955\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.6120837474265136\n",
            "  batch 4000 accuracy: 0.7925\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.6207171594332903\n",
            "  batch 5000 accuracy: 0.793625\n",
            "-----------------------------------------------------------------------\n",
            "  batch 6000 loss: 0.6046526396498084\n",
            "  batch 6000 accuracy: 0.795625\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.5682341398391872\n",
            "  avg_vaccuracy: 0.807\n",
            "\n",
            "\n",
            "EPOCH 8:\n",
            "  batch 1000 loss: 0.5803125112056732\n",
            "  batch 1000 accuracy: 0.805375\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.5868830824708566\n",
            "  batch 2000 accuracy: 0.804875\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.5845169559856876\n",
            "  batch 3000 accuracy: 0.80275\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.5875726966671646\n",
            "  batch 4000 accuracy: 0.803125\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.5900790261141956\n",
            "  batch 5000 accuracy: 0.800875\n",
            "-----------------------------------------------------------------------\n",
            "  batch 6000 loss: 0.5997924226410687\n",
            "  batch 6000 accuracy: 0.796625\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.5322427910592407\n",
            "  avg_vaccuracy: 0.8209\n",
            "\n",
            "\n",
            "EPOCH 9:\n",
            "  batch 1000 loss: 0.5433398410156369\n",
            "  batch 1000 accuracy: 0.81275\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.5618921629078686\n",
            "  batch 2000 accuracy: 0.8115\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.5589886951269581\n",
            "  batch 3000 accuracy: 0.806375\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.5578568129874766\n",
            "  batch 4000 accuracy: 0.80875\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.5677136476542801\n",
            "  batch 5000 accuracy: 0.81175\n",
            "-----------------------------------------------------------------------\n",
            "  batch 6000 loss: 0.563102360451594\n",
            "  batch 6000 accuracy: 0.80775\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.5379650288432837\n",
            "  avg_vaccuracy: 0.8188\n",
            "\n",
            "\n",
            "EPOCH 10:\n",
            "  batch 1000 loss: 0.5440116560701281\n",
            "  batch 1000 accuracy: 0.82\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.5392858659503982\n",
            "  batch 2000 accuracy: 0.819\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.5451215575593523\n",
            "  batch 3000 accuracy: 0.813\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.5579209509361536\n",
            "  batch 4000 accuracy: 0.810125\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.5457414406333119\n",
            "  batch 5000 accuracy: 0.81275\n",
            "-----------------------------------------------------------------------\n",
            "  batch 6000 loss: 0.5682857832266017\n",
            "  batch 6000 accuracy: 0.80925\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.5248796781182289\n",
            "  avg_vaccuracy: 0.8229\n",
            "Trigger Times: 1\n",
            "trigger times: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "di6tGm8DNM_Z"
      },
      "outputs": [],
      "source": [
        "# dataiter = iter(validation_loader)\n",
        "# images, labels = dataiter.next()\n",
        "\n",
        "# # print images\n",
        "# imshow(torchvision.utils.make_grid(images))\n",
        "# print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "# images=images.to(device)\n",
        "# outputs = model(images)\n",
        "# _, predicted = torch.max(outputs, 1)\n",
        "# print('predicted : ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n",
        "\n",
        "import random\n",
        "\n",
        "\n",
        "index = random.randint(0, 2500 - 1)\n",
        "\n",
        "\n",
        "for i, data in enumerate(validation_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        if index==i:\n",
        "          inputs, labels = data\n",
        "          \n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          # Make predictions for this batch\n",
        "          outputs = model(inputs)\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          imshow(inputs[0])\n",
        "          print('labels: ',classes[labels[0]])\n",
        "          print('predicted: ',classes[predicted[0]])\n",
        "          break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "9jDmqUqiNM_d",
        "outputId": "bf8ecfba-e69d-4b65-bf9d-8d82b53cc086",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 82 %\n",
            "--------------------------------------------------------------\n",
            "\n",
            "Accuracy of airplane : 88 %\n",
            "Accuracy of automobile : 95 %\n",
            "Accuracy of  bird : 71 %\n",
            "Accuracy of   cat : 68 %\n",
            "Accuracy of  deer : 78 %\n",
            "Accuracy of   dog : 79 %\n",
            "Accuracy of  frog : 89 %\n",
            "Accuracy of horse : 85 %\n",
            "Accuracy of  ship : 82 %\n",
            "Accuracy of truck : 81 %\n"
          ]
        }
      ],
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "pred=0\n",
        "total=0\n",
        "with torch.no_grad():\n",
        "    for data in validation_loader:\n",
        "        images, labels = data\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images.to(device))\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "\n",
        "        pred += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * pred / total))\n",
        "\n",
        "print('--------------------------------------------------------------\\n')\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "    \n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "conv1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN+jq6APg0whxFPwJ3RvxTx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}