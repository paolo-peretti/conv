{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paolo-peretti/conv/blob/main/conv1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4KoLO7ooSTO7"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azkTh_eCTQsj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAPCP4B7VQ_H",
        "outputId": "c428ccf8-2bf5-40ee-bcc2-78e6bf2fc0d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqsvjRw6Wlsu"
      },
      "source": [
        "Preproccessing on dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_RH0DvcWr9K",
        "outputId": "fc7a48fe-259b-48b0-be0c-1799b5cfe9b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training set has 50000 instances\n",
            "Validation set has 10000 instances\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "# PyTorch TensorBoard support\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "# Create datasets for training & validation, download if necessary\n",
        "training_set = torchvision.datasets.CIFAR10('./data', train=True, transform=transform, download=True)\n",
        "validation_set = torchvision.datasets.CIFAR10('./data', train=False, transform=transform, download=True)\n",
        "\n",
        "\n",
        "# Create data loaders for our datasets; shuffle for training, not for validation\n",
        "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True, num_workers=2)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "# Class labels\n",
        "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "        'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Report split sizes\n",
        "print('Training set has {} instances'.format(len(training_set)))\n",
        "print('Validation set has {} instances'.format(len(validation_set)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TLqzeYManlC"
      },
      "source": [
        "I want see a grid of images of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "cttIUs4gZ_9z",
        "outputId": "371cc5fe-88db-4d8b-b2aa-e968c0c2c8bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ship\n",
            ".............................................\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Helper function for inline image display\n",
        "def imshow(img):\n",
        "    img = img.cpu()\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(training_loader)\n",
        "images, labels = dataiter.next()\n",
        "# print(len(images), len(labels))\n",
        "print(classes[labels[0]])\n",
        "print('.............................................\\n')\n",
        "imshow(images[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMsV9P1_STO9"
      },
      "source": [
        "\n",
        "\n",
        "Building The Model\n",
        "============================\n",
        "\n",
        "One important behavior of ``torch.nn.Module`` is registering parameters.\n",
        "If a particular ``Module`` subclass has learning weights, these weights\n",
        "are expressed as instances of ``torch.nn.Parameter``. The ``Parameter``\n",
        "class is a subclass of ``torch.Tensor``, with the special behavior that\n",
        "when they are assigned as attributes of a ``Module``, they are added to\n",
        "the list of that modules parameters. These parameters may be accessed\n",
        "through the ``parameters()`` method on the ``Module`` class.\n",
        "\n",
        "As a simple example, here’s a very simple model with two linear layers\n",
        "and an activation function. We’ll create an instance of it and ask it to\n",
        "report on its parameters:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWtLhhtDTdv-",
        "outputId": "f1d8dc21-042a-4c80-8da6-b6a3526754a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model:\n",
            "MyModel(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (linear1): Linear(in_features=16384, out_features=540, bias=True)\n",
            "  (linear2): Linear(in_features=540, out_features=146, bias=True)\n",
            "  (linear3): Linear(in_features=146, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "class MyModel(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        \n",
        "        # CV\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=3,out_channels=6,kernel_size=5, padding=2,stride=1)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(6)\n",
        "        \n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=6,out_channels=16,kernel_size=3, padding=1,stride=1)\n",
        "        self.bn2 = torch.nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv3 = torch.nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3, padding=1,stride=1)\n",
        "        self.bn3 = torch.nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv4 = torch.nn.Conv2d(in_channels=32,out_channels=64,kernel_size=2, padding=1,stride=1)\n",
        "        self.bn4 = torch.nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
        "\n",
        "\n",
        "        # FC\n",
        "        self.linear1 = torch.nn.Linear(64*16*16, 540)\n",
        "        self.linear2 = torch.nn.Linear(540, 146)\n",
        "        self.linear3 = torch.nn.Linear(146, 10)\n",
        "\n",
        "        # Define proportion or neurons to dropout\n",
        "        self.dropout = torch.nn.Dropout(0.25)\n",
        "\n",
        "\n",
        "        # self.softmax = torch.nn.Softmax(dim=10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn2(x)\n",
        "        # print(x.shape)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # print(x.shape)\n",
        "        # x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = x.view(-1, 64*16*16)\n",
        "        # print(x.shape)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear3(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "my_model = MyModel()\n",
        "my_model = my_model.to(device)\n",
        "\n",
        "print('The model:')\n",
        "print(my_model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jp3SazGknWr"
      },
      "source": [
        "\n",
        "Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(in_channels, out_channels, pool=False):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
        "              nn.BatchNorm2d(out_channels), \n",
        "              nn.ReLU(inplace=True)]\n",
        "    if pool: layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResNet9(torch.nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = conv_block(in_channels, 64)\n",
        "        self.conv2 = conv_block(64, 128, pool=True)\n",
        "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
        "        \n",
        "        self.conv3 = conv_block(128, 256, pool=True)\n",
        "        self.conv4 = conv_block(256, 512, pool=True)\n",
        "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
        "        \n",
        "        self.classifier = nn.Sequential(nn.MaxPool2d(4), \n",
        "                                        nn.Flatten(), \n",
        "                                        nn.Linear(512, num_classes))\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "resnet = ResNet9(3,10)\n",
        "resnet = resnet.to(device)\n",
        "print(resnet)"
      ],
      "metadata": {
        "id": "4dCd5UG5bxIl",
        "outputId": "cad56d28-1882-47aa-82b1-6d1baa339284",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet9(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (res1): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (res2): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
            "    (1): Flatten(start_dim=1, end_dim=-1)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet"
      ],
      "metadata": {
        "id": "qVDI82DEc-10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "5HzXTDFzkpa8"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEhQZ87mk3yj"
      },
      "source": [
        "The Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "KG70iA5yk4yO"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(epoch_index):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(training_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "        \n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:\n",
        "            last_loss = running_loss / 2000 # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            # tb_x = epoch_index * len(training_loader) + i + 1\n",
        "            # tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "\n",
        "    return last_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCTEK5RkBAyy",
        "outputId": "44a88027-e448-4d70-99b0-d36f8ab38dd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1:\n",
            "  batch 2000 loss: 3.0142897817194463\n",
            "  batch 4000 loss: 2.191677439548075\n",
            "  batch 6000 loss: 1.9193540464043617\n",
            "  batch 8000 loss: 1.710121527772397\n",
            "  batch 10000 loss: 1.5375204760618508\n",
            "  batch 12000 loss: 1.4369583897925913\n",
            "EPOCH 2:\n",
            "  batch 2000 loss: 1.243008901794441\n",
            "  batch 4000 loss: 1.1713544545639307\n",
            "  batch 6000 loss: 1.089473151862505\n",
            "  batch 8000 loss: 1.0095986530194059\n",
            "  batch 10000 loss: 0.9499113419220084\n",
            "  batch 12000 loss: 0.9197261777019594\n",
            "EPOCH 3:\n",
            "  batch 2000 loss: 0.8240861271996982\n",
            "  batch 4000 loss: 0.7862930224261945\n",
            "  batch 6000 loss: 0.7559496626199107\n",
            "  batch 8000 loss: 0.7350072588069597\n",
            "  batch 10000 loss: 0.7243474608770338\n",
            "  batch 12000 loss: 0.7092345884894021\n",
            "EPOCH 4:\n",
            "  batch 2000 loss: 0.5835653442653711\n",
            "  batch 4000 loss: 0.5876202646801248\n",
            "  batch 6000 loss: 0.589497551877168\n",
            "  batch 8000 loss: 0.5842366546027188\n",
            "  batch 10000 loss: 0.5917420450590289\n",
            "  batch 12000 loss: 0.5552203946279769\n",
            "EPOCH 5:\n",
            "  batch 2000 loss: 0.450067149988452\n",
            "  batch 4000 loss: 0.4606794363410172\n",
            "  batch 6000 loss: 0.4674722440268888\n",
            "  batch 8000 loss: 0.4781732012820794\n",
            "  batch 10000 loss: 0.46384146343990507\n",
            "  batch 12000 loss: 0.45257216181793775\n",
            "EPOCH 6:\n",
            "  batch 2000 loss: 0.32983214741167466\n",
            "  batch 4000 loss: 0.35927088355380693\n",
            "  batch 6000 loss: 0.3679897764149282\n",
            "  batch 8000 loss: 0.36612965397090375\n",
            "  batch 10000 loss: 0.38062424637218645\n",
            "  batch 12000 loss: 0.39383607643074175\n",
            "EPOCH 7:\n",
            "  batch 2000 loss: 0.2660584719284971\n",
            "  batch 4000 loss: 0.2755419435857948\n",
            "  batch 6000 loss: 0.28018914121288435\n",
            "  batch 8000 loss: 0.2758949587447587\n",
            "  batch 10000 loss: 0.3044046392732143\n",
            "  batch 12000 loss: 0.30727600652540626\n",
            "EPOCH 8:\n",
            "  batch 2000 loss: 0.19789303242657774\n",
            "  batch 4000 loss: 0.19258780001103867\n",
            "  batch 6000 loss: 0.22639941487687612\n",
            "  batch 8000 loss: 0.21345612268930006\n",
            "  batch 10000 loss: 0.24090172028387064\n",
            "  batch 12000 loss: 0.2581264997397618\n",
            "EPOCH 9:\n",
            "  batch 2000 loss: 0.14743295815470595\n",
            "  batch 4000 loss: 0.14767264732817198\n",
            "  batch 6000 loss: 0.1718617326502901\n",
            "  batch 8000 loss: 0.1680053891566298\n",
            "  batch 10000 loss: 0.18999766001496363\n",
            "  batch 12000 loss: 0.1889488136062558\n",
            "EPOCH 10:\n",
            "  batch 2000 loss: 0.10320098452079808\n",
            "  batch 4000 loss: 0.12924433688309828\n",
            "  batch 6000 loss: 0.1227367210411523\n",
            "  batch 8000 loss: 0.1366307048364145\n",
            "  batch 10000 loss: 0.13649266992253842\n",
            "  batch 12000 loss: 0.14031419366065362\n"
          ]
        }
      ],
      "source": [
        "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
        "epoch_number = 0\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "best_vloss = 1_000_000.\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "    # Make sure gradient tracking is on, and do a pass over the data\n",
        "    model.train(True)\n",
        "    avg_loss = train_one_epoch(epoch_number)\n",
        "\n",
        "    # We don't need gradients on to do reporting\n",
        "    model.train(False)\n",
        "\n",
        "    # running_vloss = 0.0\n",
        "    # for i, vdata in enumerate(validation_loader):\n",
        "    #     vinputs, vlabels = vdata\n",
        "    #     vinputs = vinputs.to(device)\n",
        "    #     vlabels = vlabels.to(device)\n",
        "        \n",
        "    #     voutputs = model(vinputs)\n",
        "    #     vloss = loss_fn(voutputs, vlabels)\n",
        "    #     running_vloss += vloss\n",
        "\n",
        "    # avg_vloss = running_vloss / (i + 1)\n",
        "    # print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "\n",
        "\n",
        "    # # Track best performance, and save the model's state\n",
        "    # if avg_vloss < best_vloss:\n",
        "    #     best_vloss = avg_vloss\n",
        "    #     model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
        "    #     torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    epoch_number += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'cifar10_model.pth')"
      ],
      "metadata": {
        "id": "rn_KRYbojCJZ"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "di6tGm8DNM_Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "1a04f905-1737-485d-cbf8-b0e4210d2b0a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels:  bird\n",
            "predicted:  airplane\n"
          ]
        }
      ],
      "source": [
        "# dataiter = iter(validation_loader)\n",
        "# images, labels = dataiter.next()\n",
        "\n",
        "# # print images\n",
        "# imshow(torchvision.utils.make_grid(images))\n",
        "# print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "# images=images.to(device)\n",
        "# outputs = model(images)\n",
        "# _, predicted = torch.max(outputs, 1)\n",
        "# print('predicted : ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n",
        "\n",
        "import random\n",
        "\n",
        "\n",
        "index = random.randint(0, 2500 - 1)\n",
        "\n",
        "\n",
        "for i, data in enumerate(validation_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        if index==i:\n",
        "          inputs, labels = data\n",
        "          \n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          # Make predictions for this batch\n",
        "          outputs = model(inputs)\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          imshow(inputs[0])\n",
        "          print('labels: ',classes[labels[0]])\n",
        "          print('predicted: ',classes[predicted[0]])\n",
        "          break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "9jDmqUqiNM_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bed56c15-399a-4a9b-afae-014aceefad12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 84 %\n",
            "--------------------------------------------------------------\n",
            "\n",
            "Accuracy of airplane : 95 %\n",
            "Accuracy of automobile : 93 %\n",
            "Accuracy of  bird : 72 %\n",
            "Accuracy of   cat : 69 %\n",
            "Accuracy of  deer : 89 %\n",
            "Accuracy of   dog : 73 %\n",
            "Accuracy of  frog : 91 %\n",
            "Accuracy of horse : 86 %\n",
            "Accuracy of  ship : 86 %\n",
            "Accuracy of truck : 91 %\n"
          ]
        }
      ],
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "pred=0\n",
        "total=0\n",
        "with torch.no_grad():\n",
        "    for data in validation_loader:\n",
        "        images, labels = data\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images.to(device))\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "\n",
        "        pred += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * pred / total))\n",
        "\n",
        "print('--------------------------------------------------------------\\n')\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "    \n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "conv1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNUzEYwuvHZ/C79A1eemhLz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}