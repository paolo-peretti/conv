{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paolo-peretti/conv/blob/main/conv1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "4KoLO7ooSTO7"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azkTh_eCTQsj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAPCP4B7VQ_H",
        "outputId": "88b58210-5be3-43a5-c6eb-53e759a46117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqsvjRw6Wlsu"
      },
      "source": [
        "Preproccessing on dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_RH0DvcWr9K",
        "outputId": "cb32b285-83bf-4674-c21b-18c635ce9fdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training set has 50000 instances\n",
            "Validation set has 10000 instances\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "# PyTorch TensorBoard support\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "\n",
        "stats = ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "transform = transforms.Compose(\n",
        "    [transforms.RandomCrop(32, padding=4, padding_mode='reflect'), \n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(*stats,inplace=True)])\n",
        "\n",
        "\n",
        "# Create datasets for training & validation, download if necessary\n",
        "training_set = torchvision.datasets.CIFAR10('./data', train=True, transform=transform, download=True)\n",
        "validation_set = torchvision.datasets.CIFAR10('./data', train=False, transform=transform, download=True)\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "\n",
        "# Create data loaders for our datasets; shuffle for training, not for validation\n",
        "training_loader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "\n",
        "# Class labels\n",
        "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "        'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Report split sizes\n",
        "print('Training set has {} instances'.format(len(training_set)))\n",
        "print('Validation set has {} instances'.format(len(validation_set)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TLqzeYManlC"
      },
      "source": [
        "I want see a grid of images of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "cttIUs4gZ_9z",
        "outputId": "c02b6edc-614d-4ba8-922a-59ade3fab1f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "horse\n",
            ".............................................\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Helper function for inline image display\n",
        "def imshow(img):\n",
        "    img = img.cpu()\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(training_loader)\n",
        "images, labels = dataiter.next()\n",
        "# print(len(images), len(labels))\n",
        "print(classes[labels[0]])\n",
        "print('.............................................\\n')\n",
        "imshow(images[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMsV9P1_STO9"
      },
      "source": [
        "\n",
        "\n",
        "Building The Model\n",
        "============================\n",
        "\n",
        "One important behavior of ``torch.nn.Module`` is registering parameters.\n",
        "If a particular ``Module`` subclass has learning weights, these weights\n",
        "are expressed as instances of ``torch.nn.Parameter``. The ``Parameter``\n",
        "class is a subclass of ``torch.Tensor``, with the special behavior that\n",
        "when they are assigned as attributes of a ``Module``, they are added to\n",
        "the list of that modules parameters. These parameters may be accessed\n",
        "through the ``parameters()`` method on the ``Module`` class.\n",
        "\n",
        "As a simple example, here’s a very simple model with two linear layers\n",
        "and an activation function. We’ll create an instance of it and ask it to\n",
        "report on its parameters:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWtLhhtDTdv-",
        "outputId": "f32f88dd-f15a-4534-ec39-c92e45f55580"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model:\n",
            "MyModel(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (linear1): Linear(in_features=16384, out_features=540, bias=True)\n",
            "  (linear2): Linear(in_features=540, out_features=146, bias=True)\n",
            "  (linear3): Linear(in_features=146, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "class MyModel(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        \n",
        "        # CV\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=3,out_channels=6,kernel_size=5, padding=2,stride=1)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(6)\n",
        "        \n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=6,out_channels=16,kernel_size=3, padding=1,stride=1)\n",
        "        self.bn2 = torch.nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv3 = torch.nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3, padding=1,stride=1)\n",
        "        self.bn3 = torch.nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv4 = torch.nn.Conv2d(in_channels=32,out_channels=64,kernel_size=2, padding=1,stride=1)\n",
        "        self.bn4 = torch.nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
        "\n",
        "\n",
        "        # FC\n",
        "        self.linear1 = torch.nn.Linear(64*16*16, 540)\n",
        "        self.linear2 = torch.nn.Linear(540, 146)\n",
        "        self.linear3 = torch.nn.Linear(146, 10)\n",
        "\n",
        "        # Define proportion or neurons to dropout\n",
        "        self.dropout = torch.nn.Dropout(0.25)\n",
        "\n",
        "\n",
        "        # self.softmax = torch.nn.Softmax(dim=10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn2(x)\n",
        "        # print(x.shape)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # print(x.shape)\n",
        "        # x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = x.view(-1, 64*16*16)\n",
        "        # print(x.shape)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear3(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "my_model = MyModel()\n",
        "my_model = my_model.to(device)\n",
        "\n",
        "print('The model:')\n",
        "print(my_model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jp3SazGknWr"
      },
      "source": [
        "\n",
        "Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(in_channels, out_channels, pool=False):\n",
        "\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
        "              nn.BatchNorm2d(out_channels), \n",
        "              nn.ReLU(inplace=True)]\n",
        "    if pool: layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResNet9(torch.nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Conv. Layers\n",
        "        self.conv1 = conv_block(in_channels, 64)\n",
        "        self.conv2 = conv_block(64, 128, pool=True)\n",
        "        self.conv3 = conv_block(128, 128)\n",
        "        self.conv4 = conv_block(128, 256, pool=True)\n",
        "        self.conv5 = conv_block(256, 512, pool=True)\n",
        "        self.conv6 = conv_block(512, 512)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        \n",
        "        # FN\n",
        "        self.fn1 = nn.Sequential(nn.MaxPool2d(4), \n",
        "                                        nn.Flatten(), \n",
        "                                        nn.Linear(512, 256))\n",
        "        \n",
        "        self.fn2 = nn.Linear(256, num_classes)\n",
        "        \n",
        "        self.classifier = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.conv5(out)\n",
        "        out = self.conv6(out)\n",
        "\n",
        "\n",
        "        out = self.dropout(out)\n",
        "        out = self.fn1(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fn2(out)\n",
        "        \n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "resnet = ResNet9(3,10)\n",
        "resnet = resnet.to(device)\n",
        "print(resnet)"
      ],
      "metadata": {
        "id": "4dCd5UG5bxIl",
        "outputId": "b5d50fa8-0ca9-4e11-a756-09ade463048b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet9(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv5): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv6): Sequential(\n",
            "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            "  (fn1): Sequential(\n",
            "    (0): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
            "    (1): Flatten(start_dim=1, end_dim=-1)\n",
            "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  )\n",
            "  (fn2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (classifier): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet"
      ],
      "metadata": {
        "id": "qVDI82DEc-10"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "5HzXTDFzkpa8"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEhQZ87mk3yj"
      },
      "source": [
        "The Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "metadata": {
        "id": "mX-COhixzccT"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, validation_loader):\n",
        "\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      model.eval()\n",
        "\n",
        "      running_vloss = 0.0\n",
        "      running_vacc = 0.0\n",
        "\n",
        "      for i, vdata in enumerate(validation_loader):\n",
        "\n",
        "          vinputs, vlabels = vdata\n",
        "\n",
        "          vinputs = vinputs.to(device)\n",
        "          vlabels = vlabels.to(device)\n",
        "          \n",
        "          voutputs = model(vinputs)\n",
        "          \n",
        "\n",
        "          running_vloss += loss_fn(voutputs, vlabels).item()\n",
        "        \n",
        "          running_vacc += accuracy(voutputs, vlabels).item()\n",
        "\n",
        "      avg_vloss = running_vloss / (i + 1)\n",
        "      avg_vaccuracy = running_vacc / (i + 1)\n",
        "\n",
        "      print('  avg_vloss: {}'.format(avg_vloss))\n",
        "      print('  avg_vaccuracy: {}'.format(avg_vaccuracy))\n",
        "\n",
        "      return avg_vloss, avg_vaccuracy"
      ],
      "metadata": {
        "id": "WcmgIXQSyB1q"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "KG70iA5yk4yO"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(epoch_index):\n",
        "\n",
        "    model.train()\n",
        "  \n",
        "    running_loss = 0.\n",
        "    running_accuracy = 0.\n",
        "\n",
        " \n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(training_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "        \n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "\n",
        "        running_accuracy += accuracy(outputs,labels).item()\n",
        "\n",
        "\n",
        "        if i % 1000 == 999:\n",
        "\n",
        "            last_loss = running_loss / 1000\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            last_accuracy = running_accuracy / 1000\n",
        "            print('  batch {} accuracy: {}'.format(i + 1, last_accuracy))\n",
        "            \n",
        "            running_loss = 0.\n",
        "            running_accuracy = 0.\n",
        "\n",
        "            print('-----------------------------------------------------------------------')\n",
        "  \n",
        "\n",
        "      \n",
        "    # last_loss = running_loss / (i + 1) # loss per batch\n",
        "    # last_accuracy = running_accuracy / (i + 1)\n",
        "    # print('  loss: {}'.format(last_loss))\n",
        "    # print('  accuracy: {}'.format(last_accuracy))\n",
        "    \n",
        "      \n",
        "\n",
        "    return last_loss, last_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "lCTEK5RkBAyy"
      },
      "outputs": [],
      "source": [
        "def train_data(EPOCHS):\n",
        "\n",
        "  patience = 2\n",
        "  best_vloss = 1_000_000.\n",
        "  trigger_times = 0\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "\n",
        "      print('\\n\\nEPOCH {}:'.format(epoch + 1))\n",
        "\n",
        "      model.requires_grad_(True)\n",
        "      \n",
        "      avg_loss, avg_accuracy = train_one_epoch(epoch)\n",
        "\n",
        "      model.requires_grad_(False)\n",
        "\n",
        "      vloss, vaccuracy = evaluate(model, validation_loader)\n",
        "      \n",
        "\n",
        "      # Early stopping\n",
        "        \n",
        "      if vloss > best_vloss:\n",
        "          trigger_times += 1\n",
        "          print('Trigger Times:', trigger_times)\n",
        "\n",
        "          if trigger_times >= patience:\n",
        "              print('Early stopping!\\nStart to test process.')\n",
        "              return model\n",
        "\n",
        "          else:\n",
        "              print('trigger times: 0')\n",
        "              trigger_times = 0\n",
        "\n",
        "      best_vloss = avg_loss\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = train_data(20)\n",
        "\n",
        "torch.save(model.state_dict(), 'cifar10_model.pth')\n"
      ],
      "metadata": {
        "id": "rn_KRYbojCJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f0fe96-7425-4eba-d3a0-5ff3177430e3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "EPOCH 1:\n",
            "  batch 1000 loss: 1.990404043674469\n",
            "  batch 1000 accuracy: 0.2878000058680773\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 1.6323158762454986\n",
            "  batch 2000 accuracy: 0.40330000626295803\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 1.4423482263684273\n",
            "  batch 3000 accuracy: 0.48170000656694173\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 1.3113533050119877\n",
            "  batch 4000 accuracy: 0.5316000061333179\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 1.2277115170359612\n",
            "  batch 5000 accuracy: 0.5625000054314733\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 1.1285498896539212\n",
            "  avg_vaccuracy: 0.5982000053152442\n",
            "\n",
            "\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 1.1338366720974444\n",
            "  batch 1000 accuracy: 0.601100005209446\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 1.0737616734802722\n",
            "  batch 2000 accuracy: 0.626800004594028\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 1.0274256221801044\n",
            "  batch 3000 accuracy: 0.6413000039830804\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.974077421668917\n",
            "  batch 4000 accuracy: 0.6690000040233135\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.920210361033678\n",
            "  batch 5000 accuracy: 0.6817000021636486\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.8259257961064577\n",
            "  avg_vaccuracy: 0.713000001192093\n",
            "\n",
            "\n",
            "EPOCH 3:\n",
            "  batch 1000 loss: 0.8727724101394415\n",
            "  batch 1000 accuracy: 0.6994000016599894\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.8293566203862429\n",
            "  batch 2000 accuracy: 0.7153000015318394\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.8191039441861212\n",
            "  batch 3000 accuracy: 0.716000001579523\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.8038058612942696\n",
            "  batch 4000 accuracy: 0.7294000010043382\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.7877441880851984\n",
            "  batch 5000 accuracy: 0.7317999998182059\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.7429109617248177\n",
            "  avg_vaccuracy: 0.7449000001251698\n",
            "\n",
            "\n",
            "EPOCH 4:\n",
            "  batch 1000 loss: 0.755225009150803\n",
            "  batch 1000 accuracy: 0.7427999995648861\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.721852374907583\n",
            "  batch 2000 accuracy: 0.7573999992311001\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.7067073102965951\n",
            "  batch 3000 accuracy: 0.7633999991416931\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.6950403513610363\n",
            "  batch 4000 accuracy: 0.767299999177456\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.7022974835410715\n",
            "  batch 5000 accuracy: 0.7595999989956618\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.6093244208618999\n",
            "  avg_vaccuracy: 0.7942999967038632\n",
            "\n",
            "\n",
            "EPOCH 5:\n",
            "  batch 1000 loss: 0.6648085284680129\n",
            "  batch 1000 accuracy: 0.777199998319149\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.6610612614303827\n",
            "  batch 2000 accuracy: 0.7811999975442886\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.6538917432799936\n",
            "  batch 3000 accuracy: 0.7788999980688095\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.6552375204190611\n",
            "  batch 4000 accuracy: 0.7773999979794025\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.650094407202676\n",
            "  batch 5000 accuracy: 0.7810999977588654\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.5904814376272262\n",
            "  avg_vaccuracy: 0.7978999975025654\n",
            "\n",
            "\n",
            "EPOCH 6:\n",
            "  batch 1000 loss: 0.6104493131991476\n",
            "  batch 1000 accuracy: 0.7934999971985817\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.6189185271598399\n",
            "  batch 2000 accuracy: 0.791899996638298\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.6252050736397505\n",
            "  batch 3000 accuracy: 0.7919999970495701\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.6057888651806861\n",
            "  batch 4000 accuracy: 0.7956999969035387\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.6117497037127614\n",
            "  batch 5000 accuracy: 0.7930999970138073\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.5566484257858246\n",
            "  avg_vaccuracy: 0.8130999960899353\n",
            "\n",
            "\n",
            "EPOCH 7:\n",
            "  batch 1000 loss: 0.5667365878215059\n",
            "  batch 1000 accuracy: 0.8106999968886376\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.5808225401937962\n",
            "  batch 2000 accuracy: 0.8069999970197678\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.5837686410397291\n",
            "  batch 3000 accuracy: 0.8051999970376491\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.5721622057743371\n",
            "  batch 4000 accuracy: 0.8104999970793724\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.573589990152046\n",
            "  batch 5000 accuracy: 0.8048999968767167\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.5348221025392413\n",
            "  avg_vaccuracy: 0.8178999957442283\n",
            "\n",
            "\n",
            "EPOCH 8:\n",
            "  batch 1000 loss: 0.5499458586778492\n",
            "  batch 1000 accuracy: 0.8131999956071376\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.556876361342147\n",
            "  batch 2000 accuracy: 0.811099995970726\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.556530912393704\n",
            "  batch 3000 accuracy: 0.8143999955356122\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.5501682370323688\n",
            "  batch 4000 accuracy: 0.815999995470047\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.5557125676581636\n",
            "  batch 5000 accuracy: 0.8106999965310097\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.5060245047751815\n",
            "  avg_vaccuracy: 0.8338999945223331\n",
            "\n",
            "\n",
            "EPOCH 9:\n",
            "  batch 1000 loss: 0.530210160959512\n",
            "  batch 1000 accuracy: 0.820599995881319\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.5378911311002448\n",
            "  batch 2000 accuracy: 0.821599995970726\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.5313014202900231\n",
            "  batch 3000 accuracy: 0.8179999957978725\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.5525294879376889\n",
            "  batch 4000 accuracy: 0.814799997150898\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.5380576741285622\n",
            "  batch 5000 accuracy: 0.8205999955236912\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.5200247991066426\n",
            "  avg_vaccuracy: 0.8270999955534935\n",
            "\n",
            "\n",
            "EPOCH 10:\n",
            "  batch 1000 loss: 0.510799763824325\n",
            "  batch 1000 accuracy: 0.8275999959111213\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.5211036370862275\n",
            "  batch 2000 accuracy: 0.8249999954998494\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.5267123807827011\n",
            "  batch 3000 accuracy: 0.8213999957740307\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.5187543920408935\n",
            "  batch 4000 accuracy: 0.8294999956488609\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.5142371766734868\n",
            "  batch 5000 accuracy: 0.8267999948859215\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.4890835918169469\n",
            "  avg_vaccuracy: 0.8380999948680401\n",
            "\n",
            "\n",
            "EPOCH 11:\n",
            "  batch 1000 loss: 0.5045403692135587\n",
            "  batch 1000 accuracy: 0.8316999956965446\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.5046948994733393\n",
            "  batch 2000 accuracy: 0.8290999955236912\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.5074633495006711\n",
            "  batch 3000 accuracy: 0.8306999942660331\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.5080022516176105\n",
            "  batch 4000 accuracy: 0.8295999951660633\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.5129418999459594\n",
            "  batch 5000 accuracy: 0.8276999958157539\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.4683737694267184\n",
            "  avg_vaccuracy: 0.8419999943971634\n",
            "\n",
            "\n",
            "EPOCH 12:\n",
            "  batch 1000 loss: 0.4943774757119827\n",
            "  batch 1000 accuracy: 0.8325999955832958\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.5019945902749896\n",
            "  batch 2000 accuracy: 0.8322999954223633\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.4863426186582074\n",
            "  batch 3000 accuracy: 0.8393999944031239\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.49715667754597964\n",
            "  batch 4000 accuracy: 0.8348999949991703\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.5012163567356765\n",
            "  batch 5000 accuracy: 0.8300999960005283\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.4794917455697432\n",
            "  avg_vaccuracy: 0.8393999955952167\n",
            "\n",
            "\n",
            "EPOCH 13:\n",
            "  batch 1000 loss: 0.48300653941044586\n",
            "  batch 1000 accuracy: 0.8389999948740006\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.47662758611980827\n",
            "  batch 2000 accuracy: 0.8438999955356121\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.5029876569085755\n",
            "  batch 3000 accuracy: 0.8289999952614308\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.48583560600690545\n",
            "  batch 4000 accuracy: 0.8365999951958656\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.49798937755078077\n",
            "  batch 5000 accuracy: 0.8332999953627587\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.44812210081797094\n",
            "  avg_vaccuracy: 0.8448999947011471\n",
            "\n",
            "\n",
            "EPOCH 14:\n",
            "  batch 1000 loss: 0.4695615954429377\n",
            "  batch 1000 accuracy: 0.8406999956071377\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.4742175517641008\n",
            "  batch 2000 accuracy: 0.8392999954521656\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.48642081221565603\n",
            "  batch 3000 accuracy: 0.8348999966084957\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.47928586285654456\n",
            "  batch 4000 accuracy: 0.8371999951601028\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.48506230233050884\n",
            "  batch 5000 accuracy: 0.8349999954104423\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.4579819434415549\n",
            "  avg_vaccuracy: 0.8498999942839146\n",
            "\n",
            "\n",
            "EPOCH 15:\n",
            "  batch 1000 loss: 0.48026201776601374\n",
            "  batch 1000 accuracy: 0.8393999952673912\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.4604164297305979\n",
            "  batch 2000 accuracy: 0.8436999944448471\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.4647565415324643\n",
            "  batch 3000 accuracy: 0.8444999946951867\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.4730568636227399\n",
            "  batch 4000 accuracy: 0.8440999952256679\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.4899677886944264\n",
            "  batch 5000 accuracy: 0.8369999948143959\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.4642868330096826\n",
            "  avg_vaccuracy: 0.8463999945819378\n",
            "Trigger Times: 1\n",
            "trigger times: 0\n",
            "\n",
            "\n",
            "EPOCH 16:\n",
            "  batch 1000 loss: 0.457015753951855\n",
            "  batch 1000 accuracy: 0.8492999938130379\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.45914416848123074\n",
            "  batch 2000 accuracy: 0.8461999943554401\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.4634696080368012\n",
            "  batch 3000 accuracy: 0.8423999950587749\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.47206163326092065\n",
            "  batch 4000 accuracy: 0.8431999947428703\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.47725852524861695\n",
            "  batch 5000 accuracy: 0.8421999942660332\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.4797670058272779\n",
            "  avg_vaccuracy: 0.8408999954760075\n",
            "\n",
            "\n",
            "EPOCH 17:\n",
            "  batch 1000 loss: 0.44760275158938023\n",
            "  batch 1000 accuracy: 0.8492999940216541\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.45107788595790044\n",
            "  batch 2000 accuracy: 0.8484999942481518\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.46855454880045727\n",
            "  batch 3000 accuracy: 0.844199994623661\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.4710245852856897\n",
            "  batch 4000 accuracy: 0.8409999946653843\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.4672840162329376\n",
            "  batch 5000 accuracy: 0.8445999953746796\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.4354064758233726\n",
            "  avg_vaccuracy: 0.8517999942600727\n",
            "\n",
            "\n",
            "EPOCH 18:\n",
            "  batch 1000 loss: 0.42817815831210465\n",
            "  batch 1000 accuracy: 0.8595999929308892\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.45127772591635584\n",
            "  batch 2000 accuracy: 0.8457999942898751\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.4804838557206094\n",
            "  batch 3000 accuracy: 0.8399999953210354\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.46784249390568583\n",
            "  batch 4000 accuracy: 0.8409999952614308\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.4615451150741428\n",
            "  batch 5000 accuracy: 0.84759999486804\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.44061560481972994\n",
            "  avg_vaccuracy: 0.8526999939382076\n",
            "\n",
            "\n",
            "EPOCH 19:\n",
            "  batch 1000 loss: 0.4455560899535194\n",
            "  batch 1000 accuracy: 0.8470999943315983\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.4523055250239559\n",
            "  batch 2000 accuracy: 0.8485999945998192\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.44802162251342087\n",
            "  batch 3000 accuracy: 0.8489999944269657\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.4489977138713002\n",
            "  batch 4000 accuracy: 0.8505999945104122\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.4627443476729095\n",
            "  batch 5000 accuracy: 0.8456999948620796\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.4286471040351316\n",
            "  avg_vaccuracy: 0.8549999942183495\n",
            "Trigger Times: 1\n",
            "trigger times: 0\n",
            "\n",
            "\n",
            "EPOCH 20:\n",
            "  batch 1000 loss: 0.4272970300489105\n",
            "  batch 1000 accuracy: 0.8519999942779541\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.44556365106394513\n",
            "  batch 2000 accuracy: 0.8481999945640564\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.46260070844134316\n",
            "  batch 3000 accuracy: 0.8440999944508075\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.4611879494972527\n",
            "  batch 4000 accuracy: 0.8485999937951565\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.46133698638901116\n",
            "  batch 5000 accuracy: 0.8438999952375889\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.46484020819887517\n",
            "  avg_vaccuracy: 0.8491999938189984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "di6tGm8DNM_Z",
        "outputId": "3d22466e-b3cd-47e2-e1d2-7db63dbd4d99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels:  ship\n",
            "predicted:  ship\n"
          ]
        }
      ],
      "source": [
        "# dataiter = iter(validation_loader)\n",
        "# images, labels = dataiter.next()\n",
        "\n",
        "# # print images\n",
        "# imshow(torchvision.utils.make_grid(images))\n",
        "# print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "# images=images.to(device)\n",
        "# outputs = model(images)\n",
        "# _, predicted = torch.max(outputs, 1)\n",
        "# print('predicted : ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n",
        "\n",
        "import random\n",
        "\n",
        "\n",
        "index = random.randint(0, 2500 - 1)\n",
        "\n",
        "\n",
        "for i, data in enumerate(validation_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        if index==i:\n",
        "          inputs, labels = data\n",
        "          \n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          # Make predictions for this batch\n",
        "          outputs = model(inputs)\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          imshow(inputs[0])\n",
        "          print('labels: ',classes[labels[0]])\n",
        "          print('predicted: ',classes[predicted[0]])\n",
        "          break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "9jDmqUqiNM_d",
        "outputId": "73b0d220-3f2c-498c-a2c6-5a3ce541ef7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 85 %\n",
            "--------------------------------------------------------------\n",
            "\n",
            "Accuracy of airplane : 87 %\n",
            "Accuracy of automobile : 90 %\n",
            "Accuracy of  bird : 75 %\n",
            "Accuracy of   cat : 60 %\n",
            "Accuracy of  deer : 85 %\n",
            "Accuracy of   dog : 85 %\n",
            "Accuracy of  frog : 90 %\n",
            "Accuracy of horse : 84 %\n",
            "Accuracy of  ship : 90 %\n",
            "Accuracy of truck : 93 %\n"
          ]
        }
      ],
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "pred=0\n",
        "total=0\n",
        "with torch.no_grad():\n",
        "    for data in validation_loader:\n",
        "        images, labels = data\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images.to(device))\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "\n",
        "        pred += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * pred / total))\n",
        "\n",
        "print('--------------------------------------------------------------\\n')\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "    \n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "conv1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPPfeDFlaZHdhnUUOSSrcf/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}