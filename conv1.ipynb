{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paolo-peretti/conv/blob/main/conv1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "4KoLO7ooSTO7"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azkTh_eCTQsj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAPCP4B7VQ_H",
        "outputId": "e54f8b0e-ecd6-4897-8041-74745985f88d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqsvjRw6Wlsu"
      },
      "source": [
        "Preproccessing on dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_RH0DvcWr9K",
        "outputId": "b924c8b2-6eb7-45b5-b4fc-66f898e21a02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training set has 50000 instances\n",
            "Validation set has 10000 instances\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "# PyTorch TensorBoard support\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "\n",
        "stats = ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "transform = transforms.Compose(\n",
        "    [transforms.RandomCrop(32, padding=4, padding_mode='reflect'), \n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(*stats,inplace=True)])\n",
        "\n",
        "\n",
        "# Create datasets for training & validation, download if necessary\n",
        "training_set = torchvision.datasets.CIFAR10('./data', train=True, transform=transform, download=True)\n",
        "validation_set = torchvision.datasets.CIFAR10('./data', train=False, transform=transform, download=True)\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 44\n",
        "\n",
        "\n",
        "# Create data loaders for our datasets; shuffle for training, not for validation\n",
        "training_loader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "\n",
        "# Class labels\n",
        "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "        'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Report split sizes\n",
        "print('Training set has {} instances'.format(len(training_set)))\n",
        "print('Validation set has {} instances'.format(len(validation_set)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TLqzeYManlC"
      },
      "source": [
        "I want see a grid of images of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "cttIUs4gZ_9z",
        "outputId": "eca1d8dd-1af7-45ab-822d-8481b655a097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deer\n",
            ".............................................\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Helper function for inline image display\n",
        "def imshow(img):\n",
        "    img = img.cpu()\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(training_loader)\n",
        "images, labels = dataiter.next()\n",
        "# print(len(images), len(labels))\n",
        "print(classes[labels[0]])\n",
        "print('.............................................\\n')\n",
        "imshow(images[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMsV9P1_STO9"
      },
      "source": [
        "\n",
        "\n",
        "Building The Model\n",
        "============================\n",
        "\n",
        "One important behavior of ``torch.nn.Module`` is registering parameters.\n",
        "If a particular ``Module`` subclass has learning weights, these weights\n",
        "are expressed as instances of ``torch.nn.Parameter``. The ``Parameter``\n",
        "class is a subclass of ``torch.Tensor``, with the special behavior that\n",
        "when they are assigned as attributes of a ``Module``, they are added to\n",
        "the list of that modules parameters. These parameters may be accessed\n",
        "through the ``parameters()`` method on the ``Module`` class.\n",
        "\n",
        "As a simple example, here’s a very simple model with two linear layers\n",
        "and an activation function. We’ll create an instance of it and ask it to\n",
        "report on its parameters:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWtLhhtDTdv-",
        "outputId": "1aa6c042-611c-4ece-a42a-3e4103af1e90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model:\n",
            "MyModel(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (linear1): Linear(in_features=16384, out_features=540, bias=True)\n",
            "  (linear2): Linear(in_features=540, out_features=146, bias=True)\n",
            "  (linear3): Linear(in_features=146, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "class MyModel(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        \n",
        "        # CV\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=3,out_channels=6,kernel_size=5, padding=2,stride=1)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(6)\n",
        "        \n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=6,out_channels=16,kernel_size=3, padding=1,stride=1)\n",
        "        self.bn2 = torch.nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv3 = torch.nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3, padding=1,stride=1)\n",
        "        self.bn3 = torch.nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv4 = torch.nn.Conv2d(in_channels=32,out_channels=64,kernel_size=2, padding=1,stride=1)\n",
        "        self.bn4 = torch.nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
        "\n",
        "\n",
        "        # FC\n",
        "        self.linear1 = torch.nn.Linear(64*16*16, 540)\n",
        "        self.linear2 = torch.nn.Linear(540, 146)\n",
        "        self.linear3 = torch.nn.Linear(146, 10)\n",
        "\n",
        "        # Define proportion or neurons to dropout\n",
        "        self.dropout = torch.nn.Dropout(0.25)\n",
        "\n",
        "\n",
        "        # self.softmax = torch.nn.Softmax(dim=10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn2(x)\n",
        "        # print(x.shape)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # print(x.shape)\n",
        "        # x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = x.view(-1, 64*16*16)\n",
        "        # print(x.shape)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear3(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "my_model = MyModel()\n",
        "my_model = my_model.to(device)\n",
        "\n",
        "print('The model:')\n",
        "print(my_model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jp3SazGknWr"
      },
      "source": [
        "\n",
        "Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(in_channels, out_channels, pool=False):\n",
        "\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
        "              nn.BatchNorm2d(out_channels), \n",
        "              nn.ReLU(inplace=True)]\n",
        "    if pool: layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResNet9(torch.nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Conv. Layers\n",
        "        self.conv1 = conv_block(in_channels, 64)\n",
        "        self.conv2 = conv_block(64, 128, pool=True)\n",
        "        self.conv3 = conv_block(128, 128)\n",
        "        self.conv4 = conv_block(128, 256, pool=True)\n",
        "        self.conv5 = conv_block(256, 512, pool=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        \n",
        "        # FN\n",
        "        self.fn1 = nn.Sequential(nn.MaxPool2d(4), \n",
        "                                        nn.Flatten(), \n",
        "                                        nn.Linear(512, 256))\n",
        "        \n",
        "        self.fn2 = nn.Sequential(nn.MaxPool2d(3), \n",
        "                                        nn.Flatten(), \n",
        "                                        nn.Linear(256, num_classes))\n",
        "        \n",
        "        self.classifier = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.conv5(out)\n",
        "\n",
        "        out = self.fn1(out)\n",
        "        out = self.fn2(out)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "resnet = ResNet9(3,10)\n",
        "resnet = resnet.to(device)\n",
        "print(resnet)"
      ],
      "metadata": {
        "id": "4dCd5UG5bxIl",
        "outputId": "a31a2220-95e4-4260-d279-893bec7905d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet9(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv5): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            "  (fn1): Sequential(\n",
            "    (0): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
            "    (1): Flatten(start_dim=1, end_dim=-1)\n",
            "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  )\n",
            "  (fn2): Sequential(\n",
            "    (0): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "    (1): Flatten(start_dim=1, end_dim=-1)\n",
            "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  )\n",
            "  (classifier): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet"
      ],
      "metadata": {
        "id": "qVDI82DEc-10"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "5HzXTDFzkpa8"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEhQZ87mk3yj"
      },
      "source": [
        "The Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "metadata": {
        "id": "mX-COhixzccT"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, validation_loader):\n",
        "\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      model.eval()\n",
        "\n",
        "      running_vloss = 0.0\n",
        "      running_vacc = 0.0\n",
        "\n",
        "      for i, vdata in enumerate(validation_loader):\n",
        "\n",
        "          vinputs, vlabels = vdata\n",
        "\n",
        "          vinputs = vinputs.to(device)\n",
        "          vlabels = vlabels.to(device)\n",
        "          \n",
        "          voutputs = model(vinputs)\n",
        "          \n",
        "\n",
        "          running_vloss += loss_fn(voutputs, vlabels).item()\n",
        "        \n",
        "          running_vacc += accuracy(voutputs, vlabels).item()\n",
        "\n",
        "      avg_vloss = running_vloss / (i + 1)\n",
        "      avg_vaccuracy = running_vacc / (i + 1)\n",
        "\n",
        "      print('  avg_vloss: {}'.format(avg_vloss))\n",
        "      print('  avg_vaccuracy: {}'.format(avg_vaccuracy))\n",
        "\n",
        "      return avg_vloss, avg_vaccuracy"
      ],
      "metadata": {
        "id": "WcmgIXQSyB1q"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "KG70iA5yk4yO"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(epoch_index):\n",
        "\n",
        "    model.train()\n",
        "  \n",
        "    running_loss = 0.\n",
        "    running_accuracy = 0.\n",
        "\n",
        " \n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(training_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "        \n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "\n",
        "        running_accuracy += accuracy(outputs,labels).item()\n",
        "\n",
        "\n",
        "        if i % 1000 == 999:\n",
        "\n",
        "            last_loss = running_loss / 1000\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            last_accuracy = running_accuracy / 1000\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_accuracy))\n",
        "            \n",
        "            running_loss = 0.\n",
        "            running_accuracy = 0.\n",
        "\n",
        "            print('-----------------------------------------------------------------------')\n",
        "  \n",
        "\n",
        "      \n",
        "    # last_loss = running_loss / (i + 1) # loss per batch\n",
        "    # last_accuracy = running_accuracy / (i + 1)\n",
        "    # print('  loss: {}'.format(last_loss))\n",
        "    # print('  accuracy: {}'.format(last_accuracy))\n",
        "    \n",
        "      \n",
        "\n",
        "    return last_loss, last_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "lCTEK5RkBAyy"
      },
      "outputs": [],
      "source": [
        "def train_data(EPOCHS):\n",
        "\n",
        "  patience = 2\n",
        "  best_vloss = 1_000_000.\n",
        "  triggertimes = 0\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "\n",
        "      print('\\n\\nEPOCH {}:'.format(epoch + 1))\n",
        "\n",
        "      model.requires_grad_(True)\n",
        "      \n",
        "      avg_loss, avg_accuracy = train_one_epoch(epoch)\n",
        "\n",
        "      model.requires_grad_(False)\n",
        "\n",
        "      vloss, vaccuracy = evaluate(model, validation_loader)\n",
        "      \n",
        "\n",
        "      # Early stopping\n",
        "        \n",
        "      if avg_loss > best_vloss:\n",
        "          trigger_times += 1\n",
        "          print('Trigger Times:', trigger_times)\n",
        "\n",
        "          if trigger_times >= patience:\n",
        "              print('Early stopping!\\nStart to test process.')\n",
        "              return model\n",
        "\n",
        "          else:\n",
        "              print('trigger times: 0')\n",
        "              trigger_times = 0\n",
        "\n",
        "      best_vloss = avg_loss\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = train_data(10)\n",
        "\n",
        "torch.save(model.state_dict(), 'cifar10_model.pth')\n"
      ],
      "metadata": {
        "id": "rn_KRYbojCJZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "577b6b9c-61e1-4d49-ce26-2f0fb214da7b"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "EPOCH 1:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-154-625fc9236a3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cifar10_model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-153-5ccd6081383d>\u001b[0m in \u001b[0;36mtrain_data\u001b[0;34m(EPOCHS)\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mavg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-152-98744c8ab5c2>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch_index)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Make predictions for this batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Compute the loss and its gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-147-7f36ade9cdbc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xb)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[1;32m    163\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                             self.return_indices)\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: non-empty 3D or 4D (batch mode) tensor expected for input"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "di6tGm8DNM_Z"
      },
      "outputs": [],
      "source": [
        "# dataiter = iter(validation_loader)\n",
        "# images, labels = dataiter.next()\n",
        "\n",
        "# # print images\n",
        "# imshow(torchvision.utils.make_grid(images))\n",
        "# print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "# images=images.to(device)\n",
        "# outputs = model(images)\n",
        "# _, predicted = torch.max(outputs, 1)\n",
        "# print('predicted : ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n",
        "\n",
        "import random\n",
        "\n",
        "\n",
        "index = random.randint(0, 2500 - 1)\n",
        "\n",
        "\n",
        "for i, data in enumerate(validation_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        if index==i:\n",
        "          inputs, labels = data\n",
        "          \n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          # Make predictions for this batch\n",
        "          outputs = model(inputs)\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          imshow(inputs[0])\n",
        "          print('labels: ',classes[labels[0]])\n",
        "          print('predicted: ',classes[predicted[0]])\n",
        "          break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jDmqUqiNM_d"
      },
      "outputs": [],
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "pred=0\n",
        "total=0\n",
        "with torch.no_grad():\n",
        "    for data in validation_loader:\n",
        "        images, labels = data\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images.to(device))\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "\n",
        "        pred += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * pred / total))\n",
        "\n",
        "print('--------------------------------------------------------------\\n')\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "    \n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "conv1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMwNV42Mw7cp+4b5kZ+eXTR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}