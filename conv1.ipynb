{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paolo-peretti/conv/blob/main/conv1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "4KoLO7ooSTO7"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azkTh_eCTQsj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAPCP4B7VQ_H",
        "outputId": "21c26ceb-8870-469a-898d-4e58d0fe368c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqsvjRw6Wlsu"
      },
      "source": [
        "Preproccessing on dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_RH0DvcWr9K",
        "outputId": "13a01038-3bd1-4552-ed06-4833c173b02c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training set has 50000 instances\n",
            "Validation set has 10000 instances\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "# PyTorch TensorBoard support\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "\n",
        "stats = ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "transform = transforms.Compose(\n",
        "    [transforms.RandomCrop(32, padding=4, padding_mode='reflect'), \n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(*stats,inplace=True)])\n",
        "\n",
        "\n",
        "# Create datasets for training & validation, download if necessary\n",
        "training_set = torchvision.datasets.CIFAR10('./data', train=True, transform=transform, download=True)\n",
        "validation_set = torchvision.datasets.CIFAR10('./data', train=False, transform=transform, download=True)\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 400\n",
        "\n",
        "\n",
        "# Create data loaders for our datasets; shuffle for training, not for validation\n",
        "training_loader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "\n",
        "# Class labels\n",
        "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "        'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Report split sizes\n",
        "print('Training set has {} instances'.format(len(training_set)))\n",
        "print('Validation set has {} instances'.format(len(validation_set)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TLqzeYManlC"
      },
      "source": [
        "I want see a grid of images of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "cttIUs4gZ_9z",
        "outputId": "450e5849-f503-48f7-ba3b-4f163d7eb9c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n",
            ".............................................\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Helper function for inline image display\n",
        "def imshow(img):\n",
        "    img = img.cpu()\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(training_loader)\n",
        "images, labels = dataiter.next()\n",
        "# print(len(images), len(labels))\n",
        "print(classes[labels[0]])\n",
        "print('.............................................\\n')\n",
        "imshow(images[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMsV9P1_STO9"
      },
      "source": [
        "\n",
        "\n",
        "Building The Model\n",
        "============================\n",
        "\n",
        "One important behavior of ``torch.nn.Module`` is registering parameters.\n",
        "If a particular ``Module`` subclass has learning weights, these weights\n",
        "are expressed as instances of ``torch.nn.Parameter``. The ``Parameter``\n",
        "class is a subclass of ``torch.Tensor``, with the special behavior that\n",
        "when they are assigned as attributes of a ``Module``, they are added to\n",
        "the list of that modules parameters. These parameters may be accessed\n",
        "through the ``parameters()`` method on the ``Module`` class.\n",
        "\n",
        "As a simple example, here’s a very simple model with two linear layers\n",
        "and an activation function. We’ll create an instance of it and ask it to\n",
        "report on its parameters:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWtLhhtDTdv-",
        "outputId": "91aafb00-5cbc-46c1-cbb2-ad610ae520f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model:\n",
            "MyModel(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (linear1): Linear(in_features=16384, out_features=540, bias=True)\n",
            "  (linear2): Linear(in_features=540, out_features=146, bias=True)\n",
            "  (linear3): Linear(in_features=146, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "class MyModel(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        \n",
        "        # CV\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=3,out_channels=6,kernel_size=5, padding=2,stride=1)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(6)\n",
        "        \n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=6,out_channels=16,kernel_size=3, padding=1,stride=1)\n",
        "        self.bn2 = torch.nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv3 = torch.nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3, padding=1,stride=1)\n",
        "        self.bn3 = torch.nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv4 = torch.nn.Conv2d(in_channels=32,out_channels=64,kernel_size=2, padding=1,stride=1)\n",
        "        self.bn4 = torch.nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
        "\n",
        "\n",
        "        # FC\n",
        "        self.linear1 = torch.nn.Linear(64*16*16, 540)\n",
        "        self.linear2 = torch.nn.Linear(540, 146)\n",
        "        self.linear3 = torch.nn.Linear(146, 10)\n",
        "\n",
        "        # Define proportion or neurons to dropout\n",
        "        self.dropout = torch.nn.Dropout(0.25)\n",
        "\n",
        "\n",
        "        # self.softmax = torch.nn.Softmax(dim=10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn2(x)\n",
        "        # print(x.shape)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # print(x.shape)\n",
        "        # x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = x.view(-1, 64*16*16)\n",
        "        # print(x.shape)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear3(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "my_model = MyModel()\n",
        "my_model = my_model.to(device)\n",
        "\n",
        "print('The model:')\n",
        "print(my_model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jp3SazGknWr"
      },
      "source": [
        "\n",
        "Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(in_channels, out_channels, pool=False):\n",
        "  \n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
        "              nn.BatchNorm2d(out_channels), \n",
        "              nn.ReLU(inplace=True)]\n",
        "    if pool: layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResNet9(torch.nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = conv_block(in_channels, 64)\n",
        "        self.conv2 = conv_block(64, 128, pool=True)\n",
        "        self.conv3 = conv_block(128, 256, pool=True)\n",
        "        self.conv4 = conv_block(256, 512, pool=True)\n",
        "        \n",
        "        self.classifier = nn.Sequential(nn.MaxPool2d(4), \n",
        "                                        nn.Flatten(), \n",
        "                                        nn.Linear(512, num_classes))\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "resnet = ResNet9(3,10)\n",
        "resnet = resnet.to(device)\n",
        "print(resnet)"
      ],
      "metadata": {
        "id": "4dCd5UG5bxIl",
        "outputId": "e6876f92-5566-4f86-ce4a-6c337ef821c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet9(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
            "    (1): Flatten(start_dim=1, end_dim=-1)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet"
      ],
      "metadata": {
        "id": "qVDI82DEc-10"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "5HzXTDFzkpa8"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEhQZ87mk3yj"
      },
      "source": [
        "The Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "metadata": {
        "id": "mX-COhixzccT"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, validation_loader):\n",
        "\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      model.eval()\n",
        "\n",
        "      running_vloss = 0.0\n",
        "      running_vacc = 0.0\n",
        "\n",
        "      for i, vdata in enumerate(validation_loader):\n",
        "\n",
        "          vinputs, vlabels = vdata\n",
        "\n",
        "          vinputs = vinputs.to(device)\n",
        "          vlabels = vlabels.to(device)\n",
        "          \n",
        "          voutputs = model(vinputs)\n",
        "          \n",
        "\n",
        "          running_vloss += loss_fn(voutputs, vlabels).item()\n",
        "        \n",
        "          running_vacc += accuracy(voutputs, vlabels).item()\n",
        "\n",
        "      avg_vloss = running_vloss / (i + 1)\n",
        "      avg_vaccuracy = running_vacc / (i + 1)\n",
        "\n",
        "      print('  avg_vloss: {}'.format(avg_vloss))\n",
        "      print('  avg_vaccuracy: {}'.format(avg_vaccuracy))\n",
        "\n",
        "      return avg_vloss, avg_vaccuracy"
      ],
      "metadata": {
        "id": "WcmgIXQSyB1q"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "KG70iA5yk4yO"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(epoch_index):\n",
        "\n",
        "    model.train()\n",
        "  \n",
        "    running_loss = 0.\n",
        "    running_accuracy = 0.\n",
        "\n",
        " \n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(training_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "        \n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "\n",
        "        running_accuracy += accuracy(outputs,labels).item()\n",
        "  \n",
        "\n",
        "      \n",
        "    last_loss = running_loss / (i + 1) # loss per batch\n",
        "    last_accuracy = running_accuracy / (i + 1)\n",
        "    print('  loss: {}'.format(last_loss))\n",
        "    print('  accuracy: {}'.format(last_accuracy))\n",
        "    print('-----------------------------------------------------------------------')\n",
        "      \n",
        "\n",
        "    return last_loss, last_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "lCTEK5RkBAyy"
      },
      "outputs": [],
      "source": [
        "def train_data(EPOCHS):\n",
        "\n",
        "  patience = 2\n",
        "  best_vloss = 1_000_000.\n",
        "  triggertimes = 0\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "\n",
        "      print('\\n\\nEPOCH {}:'.format(epoch + 1))\n",
        "\n",
        "      model.requires_grad_(True)\n",
        "      \n",
        "      avg_loss, avg_accuracy = train_one_epoch(epoch)\n",
        "\n",
        "      model.requires_grad_(False)\n",
        "\n",
        "      vloss, vaccuracy = evaluate(model, validation_loader)\n",
        "      \n",
        "\n",
        "      # Early stopping\n",
        "        \n",
        "      if avg_loss > best_vloss:\n",
        "          trigger_times += 1\n",
        "          print('Trigger Times:', trigger_times)\n",
        "\n",
        "          if trigger_times >= patience:\n",
        "              print('Early stopping!\\nStart to test process.')\n",
        "              return model\n",
        "\n",
        "          else:\n",
        "              print('trigger times: 0')\n",
        "              trigger_times = 0\n",
        "\n",
        "      best_vloss = avg_loss\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = train_data(10)\n",
        "\n",
        "torch.save(model.state_dict(), 'cifar10_model.pth')\n"
      ],
      "metadata": {
        "id": "rn_KRYbojCJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c7a4817-59bd-4bfa-9c61-b5eaa3aa4e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "EPOCH 1:\n",
            "  loss: 1.328355803012848\n",
            "  accuracy: 0.5342400006055832\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 1.1064579534530639\n",
            "  avg_vaccuracy: 0.6144000029563904\n",
            "\n",
            "\n",
            "EPOCH 2:\n",
            "  loss: 0.8503553385734558\n",
            "  accuracy: 0.7105200018882751\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.8632788777351379\n",
            "  avg_vaccuracy: 0.6937999963760376\n",
            "\n",
            "\n",
            "EPOCH 3:\n",
            "  loss: 0.6911573433876037\n",
            "  accuracy: 0.7652199983596801\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.7631472754478454\n",
            "  avg_vaccuracy: 0.7398000049591065\n",
            "\n",
            "\n",
            "EPOCH 4:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "di6tGm8DNM_Z"
      },
      "outputs": [],
      "source": [
        "# dataiter = iter(validation_loader)\n",
        "# images, labels = dataiter.next()\n",
        "\n",
        "# # print images\n",
        "# imshow(torchvision.utils.make_grid(images))\n",
        "# print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "# images=images.to(device)\n",
        "# outputs = model(images)\n",
        "# _, predicted = torch.max(outputs, 1)\n",
        "# print('predicted : ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n",
        "\n",
        "import random\n",
        "\n",
        "\n",
        "index = random.randint(0, 2500 - 1)\n",
        "\n",
        "\n",
        "for i, data in enumerate(validation_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        if index==i:\n",
        "          inputs, labels = data\n",
        "          \n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          # Make predictions for this batch\n",
        "          outputs = model(inputs)\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          imshow(inputs[0])\n",
        "          print('labels: ',classes[labels[0]])\n",
        "          print('predicted: ',classes[predicted[0]])\n",
        "          break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jDmqUqiNM_d"
      },
      "outputs": [],
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "pred=0\n",
        "total=0\n",
        "with torch.no_grad():\n",
        "    for data in validation_loader:\n",
        "        images, labels = data\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images.to(device))\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "\n",
        "        pred += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * pred / total))\n",
        "\n",
        "print('--------------------------------------------------------------\\n')\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "    \n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "conv1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMmAFWrrRNtg0v3yuGZxNjS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}