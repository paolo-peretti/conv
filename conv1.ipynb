{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paolo-peretti/conv/blob/main/conv1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "id": "4KoLO7ooSTO7"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azkTh_eCTQsj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAPCP4B7VQ_H",
        "outputId": "6e15a0b9-fcc6-4c94-f0d9-c5b7d0282daf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqsvjRw6Wlsu"
      },
      "source": [
        "Preproccessing on dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_RH0DvcWr9K",
        "outputId": "6caeb23c-c325-476f-ff8a-8e3c586a604b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training set has 50000 instances\n",
            "Validation set has 10000 instances\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "# PyTorch TensorBoard support\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "\n",
        "stats = ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "transform = transforms.Compose(\n",
        "    [transforms.RandomCrop(32, padding=4, padding_mode='reflect'), \n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(*stats,inplace=True)])\n",
        "\n",
        "\n",
        "# Create datasets for training & validation, download if necessary\n",
        "training_set = torchvision.datasets.CIFAR10('./data', train=True, transform=transform, download=True)\n",
        "validation_set = torchvision.datasets.CIFAR10('./data', train=False, transform=transform, download=True)\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "\n",
        "# Create data loaders for our datasets; shuffle for training, not for validation\n",
        "training_loader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "\n",
        "# Class labels\n",
        "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "        'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Report split sizes\n",
        "print('Training set has {} instances'.format(len(training_set)))\n",
        "print('Validation set has {} instances'.format(len(validation_set)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TLqzeYManlC"
      },
      "source": [
        "I want see a grid of images of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "cttIUs4gZ_9z",
        "outputId": "5cbb0c71-0c9e-4c29-fd6b-33b6455281c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frog\n",
            ".............................................\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Helper function for inline image display\n",
        "def imshow(img):\n",
        "    img = img.cpu()\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(training_loader)\n",
        "images, labels = dataiter.next()\n",
        "# print(len(images), len(labels))\n",
        "print(classes[labels[0]])\n",
        "print('.............................................\\n')\n",
        "imshow(images[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMsV9P1_STO9"
      },
      "source": [
        "\n",
        "\n",
        "Building The Model\n",
        "============================\n",
        "\n",
        "One important behavior of ``torch.nn.Module`` is registering parameters.\n",
        "If a particular ``Module`` subclass has learning weights, these weights\n",
        "are expressed as instances of ``torch.nn.Parameter``. The ``Parameter``\n",
        "class is a subclass of ``torch.Tensor``, with the special behavior that\n",
        "when they are assigned as attributes of a ``Module``, they are added to\n",
        "the list of that modules parameters. These parameters may be accessed\n",
        "through the ``parameters()`` method on the ``Module`` class.\n",
        "\n",
        "As a simple example, here’s a very simple model with two linear layers\n",
        "and an activation function. We’ll create an instance of it and ask it to\n",
        "report on its parameters:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWtLhhtDTdv-",
        "outputId": "a9fa6a52-2c0c-4f95-cb55-1f6b6bccab3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model:\n",
            "MyModel(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (linear1): Linear(in_features=16384, out_features=540, bias=True)\n",
            "  (linear2): Linear(in_features=540, out_features=146, bias=True)\n",
            "  (linear3): Linear(in_features=146, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "class MyModel(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        \n",
        "        # CV\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=3,out_channels=6,kernel_size=5, padding=2,stride=1)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(6)\n",
        "        \n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=6,out_channels=16,kernel_size=3, padding=1,stride=1)\n",
        "        self.bn2 = torch.nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv3 = torch.nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3, padding=1,stride=1)\n",
        "        self.bn3 = torch.nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv4 = torch.nn.Conv2d(in_channels=32,out_channels=64,kernel_size=2, padding=1,stride=1)\n",
        "        self.bn4 = torch.nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
        "\n",
        "\n",
        "        # FC\n",
        "        self.linear1 = torch.nn.Linear(64*16*16, 540)\n",
        "        self.linear2 = torch.nn.Linear(540, 146)\n",
        "        self.linear3 = torch.nn.Linear(146, 10)\n",
        "\n",
        "        # Define proportion or neurons to dropout\n",
        "        self.dropout = torch.nn.Dropout(0.25)\n",
        "\n",
        "\n",
        "        # self.softmax = torch.nn.Softmax(dim=10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn2(x)\n",
        "        # print(x.shape)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # print(x.shape)\n",
        "        # x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = x.view(-1, 64*16*16)\n",
        "        # print(x.shape)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear3(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "my_model = MyModel()\n",
        "my_model = my_model.to(device)\n",
        "\n",
        "print('The model:')\n",
        "print(my_model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jp3SazGknWr"
      },
      "source": [
        "\n",
        "Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(in_channels, out_channels, pool=False):\n",
        "\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
        "              nn.BatchNorm2d(out_channels), \n",
        "              nn.ReLU(inplace=True)]\n",
        "    if pool: layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResNet9(torch.nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Conv. Layers\n",
        "        self.conv1 = conv_block(in_channels, 64)\n",
        "        self.conv2 = conv_block(64, 128, pool=True)\n",
        "        self.conv3 = conv_block(128, 128)\n",
        "        self.conv4 = conv_block(128, 256, pool=True)\n",
        "        self.conv5 = conv_block(256, 512, pool=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        \n",
        "        # FN\n",
        "        self.fn1 = nn.Sequential(nn.MaxPool2d(4), \n",
        "                                        nn.Flatten(), \n",
        "                                        nn.Linear(512, 256))\n",
        "        \n",
        "        self.fn2 = nn.Linear(256, num_classes)\n",
        "        \n",
        "        self.classifier = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.conv5(out)\n",
        "\n",
        "        out = self.fn1(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fn2(out)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "resnet = ResNet9(3,10)\n",
        "resnet = resnet.to(device)\n",
        "print(resnet)"
      ],
      "metadata": {
        "id": "4dCd5UG5bxIl",
        "outputId": "053e2e7f-d2cf-4509-cd3c-4a1b399008b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet9(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv5): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            "  (fn1): Sequential(\n",
            "    (0): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
            "    (1): Flatten(start_dim=1, end_dim=-1)\n",
            "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  )\n",
            "  (fn2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (classifier): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet"
      ],
      "metadata": {
        "id": "qVDI82DEc-10"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "5HzXTDFzkpa8"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEhQZ87mk3yj"
      },
      "source": [
        "The Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "metadata": {
        "id": "mX-COhixzccT"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, validation_loader):\n",
        "\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      model.eval()\n",
        "\n",
        "      running_vloss = 0.0\n",
        "      running_vacc = 0.0\n",
        "\n",
        "      for i, vdata in enumerate(validation_loader):\n",
        "\n",
        "          vinputs, vlabels = vdata\n",
        "\n",
        "          vinputs = vinputs.to(device)\n",
        "          vlabels = vlabels.to(device)\n",
        "          \n",
        "          voutputs = model(vinputs)\n",
        "          \n",
        "\n",
        "          running_vloss += loss_fn(voutputs, vlabels).item()\n",
        "        \n",
        "          running_vacc += accuracy(voutputs, vlabels).item()\n",
        "\n",
        "      avg_vloss = running_vloss / (i + 1)\n",
        "      avg_vaccuracy = running_vacc / (i + 1)\n",
        "\n",
        "      print('  avg_vloss: {}'.format(avg_vloss))\n",
        "      print('  avg_vaccuracy: {}'.format(avg_vaccuracy))\n",
        "\n",
        "      return avg_vloss, avg_vaccuracy"
      ],
      "metadata": {
        "id": "WcmgIXQSyB1q"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "id": "KG70iA5yk4yO"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(epoch_index):\n",
        "\n",
        "    model.train()\n",
        "  \n",
        "    running_loss = 0.\n",
        "    running_accuracy = 0.\n",
        "\n",
        " \n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(training_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "        \n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "\n",
        "        running_accuracy += accuracy(outputs,labels).item()\n",
        "\n",
        "\n",
        "        if i % 1000 == 999:\n",
        "\n",
        "            last_loss = running_loss / 1000\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            last_accuracy = running_accuracy / 1000\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_accuracy))\n",
        "            \n",
        "            running_loss = 0.\n",
        "            running_accuracy = 0.\n",
        "\n",
        "            print('-----------------------------------------------------------------------')\n",
        "  \n",
        "\n",
        "      \n",
        "    # last_loss = running_loss / (i + 1) # loss per batch\n",
        "    # last_accuracy = running_accuracy / (i + 1)\n",
        "    # print('  loss: {}'.format(last_loss))\n",
        "    # print('  accuracy: {}'.format(last_accuracy))\n",
        "    \n",
        "      \n",
        "\n",
        "    return last_loss, last_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "id": "lCTEK5RkBAyy"
      },
      "outputs": [],
      "source": [
        "def train_data(EPOCHS):\n",
        "\n",
        "  patience = 2\n",
        "  best_vloss = 1_000_000.\n",
        "  triggertimes = 0\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "\n",
        "      print('\\n\\nEPOCH {}:'.format(epoch + 1))\n",
        "\n",
        "      model.requires_grad_(True)\n",
        "      \n",
        "      avg_loss, avg_accuracy = train_one_epoch(epoch)\n",
        "\n",
        "      model.requires_grad_(False)\n",
        "\n",
        "      vloss, vaccuracy = evaluate(model, validation_loader)\n",
        "      \n",
        "\n",
        "      # Early stopping\n",
        "        \n",
        "      if avg_loss > best_vloss:\n",
        "          trigger_times += 1\n",
        "          print('Trigger Times:', trigger_times)\n",
        "\n",
        "          if trigger_times >= patience:\n",
        "              print('Early stopping!\\nStart to test process.')\n",
        "              return model\n",
        "\n",
        "          else:\n",
        "              print('trigger times: 0')\n",
        "              trigger_times = 0\n",
        "\n",
        "      best_vloss = avg_loss\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = train_data(10)\n",
        "\n",
        "torch.save(model.state_dict(), 'cifar10_model.pth')\n"
      ],
      "metadata": {
        "id": "rn_KRYbojCJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d09694-4e28-4d44-86c0-97b2b5695a90"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "EPOCH 1:\n",
            "  batch 1000 loss: 2.002360302686691\n",
            "  batch 1000 loss: 0.2696000053733587\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 1.673065272808075\n",
            "  batch 2000 loss: 0.3873000068217516\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 1.4916293941140175\n",
            "  batch 3000 loss: 0.4557000069692731\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 1.3317341075241567\n",
            "  batch 4000 loss: 0.5261000055521726\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 1.2341691697835921\n",
            "  batch 5000 loss: 0.5529000059142709\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 1.3057999312579631\n",
            "  avg_vaccuracy: 0.5305000061839819\n",
            "\n",
            "\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 1.1538500355780124\n",
            "  batch 1000 loss: 0.5917000055313111\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 1.0878540984988212\n",
            "  batch 2000 loss: 0.6151000042334199\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 1.0418295787870884\n",
            "  batch 3000 loss: 0.6291000045090914\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.9822194741964341\n",
            "  batch 4000 loss: 0.6524000038057566\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.9389185553193092\n",
            "  batch 5000 loss: 0.6680000031143427\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.7872916110754014\n",
            "  avg_vaccuracy: 0.7271000009477139\n",
            "\n",
            "\n",
            "EPOCH 3:\n",
            "  batch 1000 loss: 0.8861115579232574\n",
            "  batch 1000 loss: 0.6881000023782253\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.8421836609318852\n",
            "  batch 2000 loss: 0.7070000013485551\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.8176365532428026\n",
            "  batch 3000 loss: 0.7199000014364719\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.7923535861819982\n",
            "  batch 4000 loss: 0.7246999995112419\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.7794873471930623\n",
            "  batch 5000 loss: 0.7295000007599592\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.7086012003868818\n",
            "  avg_vaccuracy: 0.7581999990940094\n",
            "\n",
            "\n",
            "EPOCH 4:\n",
            "  batch 1000 loss: 0.7199978085272014\n",
            "  batch 1000 loss: 0.7549999995678663\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.7329637712910771\n",
            "  batch 2000 loss: 0.7499999991357327\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.6956836942657828\n",
            "  batch 3000 loss: 0.759399998307228\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.6880310391224921\n",
            "  batch 4000 loss: 0.7608999992012978\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.6747898300886154\n",
            "  batch 5000 loss: 0.7642999985516071\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.639753018822521\n",
            "  avg_vaccuracy: 0.7850999980270863\n",
            "\n",
            "\n",
            "EPOCH 5:\n",
            "  batch 1000 loss: 0.6402756880037487\n",
            "  batch 1000 loss: 0.7791999977231026\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.6405802308209241\n",
            "  batch 2000 loss: 0.7781999979317188\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.6324150112327188\n",
            "  batch 3000 loss: 0.7851999970376492\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.6203653140887618\n",
            "  batch 4000 loss: 0.7887999974787235\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.6173808539863676\n",
            "  batch 5000 loss: 0.7866999977231026\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.5834426837339998\n",
            "  avg_vaccuracy: 0.8043999967873097\n",
            "\n",
            "\n",
            "EPOCH 6:\n",
            "  batch 1000 loss: 0.58054408220388\n",
            "  batch 1000 loss: 0.80089999756217\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.5863634134717286\n",
            "  batch 2000 loss: 0.8005999976396561\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.5849068333078176\n",
            "  batch 3000 loss: 0.8012999965846539\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.5917598170787096\n",
            "  batch 4000 loss: 0.7986999970674514\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.5804917921945453\n",
            "  batch 5000 loss: 0.7976999957859516\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.551942379232496\n",
            "  avg_vaccuracy: 0.8089999962151051\n",
            "\n",
            "\n",
            "EPOCH 7:\n",
            "  batch 1000 loss: 0.5532907518967987\n",
            "  batch 1000 loss: 0.8148999963104725\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.5538343025930226\n",
            "  batch 2000 loss: 0.8145999956130981\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.5398630496636033\n",
            "  batch 3000 loss: 0.8164999954104424\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.5593574590161443\n",
            "  batch 4000 loss: 0.81169999627769\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.5476065076496452\n",
            "  batch 5000 loss: 0.8095999963283539\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.5391424784651027\n",
            "  avg_vaccuracy: 0.8128999966084958\n",
            "\n",
            "\n",
            "EPOCH 8:\n",
            "  batch 1000 loss: 0.5378418517657556\n",
            "  batch 1000 loss: 0.8205999964475632\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.5126695540226065\n",
            "  batch 2000 loss: 0.8288999952375888\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.5271126015670597\n",
            "  batch 3000 loss: 0.8231999964490533\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.5286846714876592\n",
            "  batch 4000 loss: 0.8221999960839749\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.5275349816484377\n",
            "  batch 5000 loss: 0.8247999951243401\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.48088900503143667\n",
            "  avg_vaccuracy: 0.8372999946475029\n",
            "\n",
            "\n",
            "EPOCH 9:\n",
            "  batch 1000 loss: 0.4986366371959448\n",
            "  batch 1000 loss: 0.8306999955177307\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.5021737409345806\n",
            "  batch 2000 loss: 0.8317999962568283\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.5117832354344427\n",
            "  batch 3000 loss: 0.8274999955296516\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.5172518521817401\n",
            "  batch 4000 loss: 0.8234999960362911\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.5066987570617348\n",
            "  batch 5000 loss: 0.8272999953627587\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.5119854450672865\n",
            "  avg_vaccuracy: 0.8260999954640865\n",
            "\n",
            "\n",
            "EPOCH 10:\n",
            "  batch 1000 loss: 0.480271452665329\n",
            "  batch 1000 loss: 0.837099995136261\n",
            "-----------------------------------------------------------------------\n",
            "  batch 2000 loss: 0.5005542722884566\n",
            "  batch 2000 loss: 0.8283999952673912\n",
            "-----------------------------------------------------------------------\n",
            "  batch 3000 loss: 0.476536869188305\n",
            "  batch 3000 loss: 0.8404999949634075\n",
            "-----------------------------------------------------------------------\n",
            "  batch 4000 loss: 0.4968103937339038\n",
            "  batch 4000 loss: 0.8345999954044819\n",
            "-----------------------------------------------------------------------\n",
            "  batch 5000 loss: 0.5016667029913515\n",
            "  batch 5000 loss: 0.828399995148182\n",
            "-----------------------------------------------------------------------\n",
            "  avg_vloss: 0.5058036368228496\n",
            "  avg_vaccuracy: 0.8275999947786331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "id": "di6tGm8DNM_Z",
        "outputId": "a4f3b00a-6b28-4210-9ae3-7ccf11dac989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels:  frog\n",
            "predicted:  frog\n"
          ]
        }
      ],
      "source": [
        "# dataiter = iter(validation_loader)\n",
        "# images, labels = dataiter.next()\n",
        "\n",
        "# # print images\n",
        "# imshow(torchvision.utils.make_grid(images))\n",
        "# print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "# images=images.to(device)\n",
        "# outputs = model(images)\n",
        "# _, predicted = torch.max(outputs, 1)\n",
        "# print('predicted : ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n",
        "\n",
        "import random\n",
        "\n",
        "\n",
        "index = random.randint(0, 2500 - 1)\n",
        "\n",
        "\n",
        "for i, data in enumerate(validation_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        if index==i:\n",
        "          inputs, labels = data\n",
        "          \n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          # Make predictions for this batch\n",
        "          outputs = model(inputs)\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          imshow(inputs[0])\n",
        "          print('labels: ',classes[labels[0]])\n",
        "          print('predicted: ',classes[predicted[0]])\n",
        "          break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "id": "9jDmqUqiNM_d",
        "outputId": "831b94fb-6c58-44d4-ff0e-6a454473132a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 82 %\n",
            "--------------------------------------------------------------\n",
            "\n",
            "Accuracy of airplane : 73 %\n",
            "Accuracy of automobile : 87 %\n",
            "Accuracy of  bird : 78 %\n",
            "Accuracy of   cat : 66 %\n",
            "Accuracy of  deer : 81 %\n",
            "Accuracy of   dog : 77 %\n",
            "Accuracy of  frog : 82 %\n",
            "Accuracy of horse : 82 %\n",
            "Accuracy of  ship : 94 %\n",
            "Accuracy of truck : 96 %\n"
          ]
        }
      ],
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "pred=0\n",
        "total=0\n",
        "with torch.no_grad():\n",
        "    for data in validation_loader:\n",
        "        images, labels = data\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images.to(device))\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "\n",
        "        pred += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * pred / total))\n",
        "\n",
        "print('--------------------------------------------------------------\\n')\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "    \n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "conv1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOx+xjpSNAxJallxYJFQDZY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}